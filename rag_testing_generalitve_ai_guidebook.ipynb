{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba1f84a9c41a4789858c0355ad71f666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_705d911093554b58b865718828077f91",
              "IPY_MODEL_34d3c17d97354854aa8ca8cb2c982892",
              "IPY_MODEL_6240ccce1aed4aa487d68dcd5fe063a0"
            ],
            "layout": "IPY_MODEL_c4cee855b2ff4b939cf22f3a1c8600bf"
          }
        },
        "705d911093554b58b865718828077f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aefe87d87d54d12980c868c0b9004e7",
            "placeholder": "​",
            "style": "IPY_MODEL_44b035844941488c938be313b1028a1e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "34d3c17d97354854aa8ca8cb2c982892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f550d50cea1446da3e90d1915f973b5",
            "max": 445021143,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c4db50717d84a0b813be57623529af9",
            "value": 445021143
          }
        },
        "6240ccce1aed4aa487d68dcd5fe063a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31a9860e03d941ef9bdfbb7346f4add9",
            "placeholder": "​",
            "style": "IPY_MODEL_8018a3cbd97244eea06c4add55559eb4",
            "value": " 445M/445M [00:05&lt;00:00, 197MB/s]"
          }
        },
        "c4cee855b2ff4b939cf22f3a1c8600bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aefe87d87d54d12980c868c0b9004e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44b035844941488c938be313b1028a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f550d50cea1446da3e90d1915f973b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4db50717d84a0b813be57623529af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31a9860e03d941ef9bdfbb7346f4add9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8018a3cbd97244eea06c4add55559eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euvsq9YFN2kL",
        "outputId": "33e2a9e6-db09-48ef-fb0f-7241b598009d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.6/973.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.4/310.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain-community\n",
        "!pip install -q langchain-core\n",
        "!pip install -q transformers[torch]\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q datasets\n",
        "!pip install -q faiss-cpu\n",
        "!pip install -q pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/20240530_resources_generalitve-ai-guidebook_01.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "C3yhJn5Na0tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFqvhEvUbEEN",
        "outputId": "ff0f9de4-3662-4a04-d4da-2dbfb23b2cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='テキスト生成 AI利活用におけるリスクへの対策ガイ\\nドブック（α版）  \\n2024（令和6）年 5月30日 \\nデジタル庁', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 0}), Document(page_content='〔ドキュメントの位置付け〕  \\n参考資料。 今後、デジタル社会推進標準ガイドラインへの編入を 検討予定  \\n \\n〔キーワード〕  \\nテキスト生成 AI、生成AI、サービス開発者、サービス提供者  \\n \\n〔概要〕  \\nテキスト生成 AIを利活用し、行政サービスや職員業務の改善の重要度が高まる中、リ\\nスクを特定し、そのリスクを受容できるレベルまでに軽減する対応もまた重要になってい\\nる。テキスト生成 AIに関連するリスクは多岐にわたるが、その多くはテキスト生成 AI固有\\nでない AIシステム全般に共通するものである。そこで、本文書では政府情報システムを対\\n象に、テキスト生成 AI固有と見られるリスクに焦点をあて、留意点を紹介する。現段階\\n（2024年5月現在）では、実践的なフレームワークやチェックリストによるガイドブックを作\\n成できるまでの知見が蓄積されていない ため、留意点の紹介にとどめる。本文書は、テキ\\nスト生成 AIをその提供形態と利活用方法で分類し、それぞれにおける想定リスクとその軽\\n減策を具体的に示したものである', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 1}), Document(page_content='改定履歴  \\n \\n改定年月日  改定箇所  改定内容  \\n2024年5月30日 複数 誤記等の軽微な修 正 \\n2024年5月29日 - 初版決定', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 2}), Document(page_content='1 \\n 目次 \\n目次 ................................ ..............................  1 \\n１ はじめに  ................................ .......................  4 \\n１.１ 目的とスコープ  ................................ ............  4 \\n１.２ 本文書で想定するテキスト生成 AIの利活用方法  ...............  6 \\n１.３ 本書の構成  ................................ ................  6 \\n１.４ 用語 ................................ ......................  6 \\n２ 新サービス企画時のテキスト生成 AI固有の留意  ....................  8 \\n２.１ テキスト生成 AIの利活用が不適切であるケースにテキスト生成 AI\\nを用いるリスク  ................................ ....................  8 \\n２.２ テキスト生成 AIの利活用が効果的なケースを見落とすリスク  ... 9 \\n1) 情報検索サービスを国民向けに展開する事例でテキスト生成 AIを適\\n切に利活用するユースケース  ................................ ...... 9 \\n2) パブリックコメントの返答作成業務にテキスト生成 AIを適切に利活\\n用するユースケース  ................................ .............  11 \\n3) 法令で決められた資格保有者等の支援についてテキスト生 成AIを適\\n切に利活用するユースケース  ................................ ..... 11 \\n4) 信頼できるデータベースと連携してテキスト生成 AIを適切に利活用\\nするユースケース  ................................ ...............  11 \\n２.３ 技術的実現可能性の検討によるリスク軽減  ...................  12 \\n２.４ 民間サービスの活用  ................................ ....... 16 \\n２.５ ２章のまとめ  ................................ .............  18 \\n３ 予算要求前時のテキスト生成 AI固有の留意点  .....................  19 \\n３.１ コスト削減に向けた検討  ................................ ... 19 \\n1) ハードウェア・ソフトウェアのコスト削減観点  ................  19 \\n2) アプリケーションのコスト削減観点  ..........................  20 \\n3) 運用業務のコスト 削減観点  ................................ .. 21 \\n4) その他のコスト削減観点  ................................ .... 22 \\n３.２ ３章 まとめ ................................ ..............  23 \\n４ 調達実施前時のテキスト生成 AI固有の留意点  .....................  24 \\n４.１ チャットでの利用の期待品質  ...............................  24 \\n４.２ バッチ処理での利用の期待品質  .............................  25 \\n４.３ 情報検索での利用の期待品質  ...............................  26 \\n４.４ 自然言語からのプログラム作成での利用の期待品質  ...........  26', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 3}), Document(page_content='2 \\n ４.５ ４章 まとめ ................................ ..............  26 \\n５ 設計・開発時のテキスト生成 AI固有の留意点  .....................  28 \\n５.１ テキスト生成 AIの生成物の品質面への懸念  ..................  28 \\n1) テキスト生成 AIを分類やラベリングに利活用するケース  ....... 28 \\n2) テキスト生成 AIの生成物を文章として扱うケース  .............  28 \\n５.２ テキスト生成 AIによる生成物の品質評価・品質保証についてのリス\\nクとその軽減策  ................................ ...................  29 \\n1) 生成結果がばらつくことに起因するリスク  ....................  30 \\n2) 生成物の品質評価が困難であることに起因するリスク  ..........  31 \\n3) テストケースのカバレッジが不十分なことに起因するリスク  .... 33 \\n4) テスト済みの生成物のみを用いる場合の工夫  ..................  35 \\n５.３ 5章 まとめ ................................ ...............  36 \\n６ サービス実施時に留意すべきテキスト生成 AI固有の留意点  .........  37 \\n６.１ 業務の実績データや利用者要望を分析できているか  ...........  37 \\n1) チャットでの利用の場合  ................................ .... 37 \\n2) バッチ処理での利用の場合  ................................ .. 37 \\n3) 情報検索での利用の場合  ................................ .... 37 \\n4) 自然言語からのプログラム作成利用の場合  ....................  38 \\n６.２ 非機能要件に関する実績データを把握しているか  .............  39 \\n1) チャット利用の場合  ................................ ........  39 \\n2) バッチ処理での利用の場合  ................................ .. 39 \\n3) 情報検索での利用の場合  ................................ .... 39 \\n4) 自然言語からのプログラム作成での利用の場合  ................  39 \\n６.３ 業務で扱うデータの品質を維持しつつ適切なライフサイクル管理を\\n行っているか  ................................ .....................  40 \\n６.４ ６章 まとめ ................................ ..............  40 \\nまとめ ................................ ...........................  41 \\n付録 ................................ .............................  42 \\n７ 提供形態ごとの想定リスク  ................................ ...... 42 \\n７.１ テキスト生成 AIを組み込んだサービスとして提供されるケースに関\\nするリスクとその軽減策  ................................ ...........  42 \\n1) ライセンスに関するリスク  ................................ .. 42 \\n2) 調達容易性に関するリスク  ................................ .. 42 \\n3) 機密性に関するリスク  ................................ ...... 43 \\n4) アップデート対応に関するリスク  ............................  43 \\n5) ベンダーロックインに関するリスク  ..........................  43', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 4}), Document(page_content='3 \\n 6) コストマネジメントに関するリスク  ..........................  44 \\n７.２ テキスト生成 AIを利用するための Web APIがクラウドサービスとし\\nて提供されるケースに関するリスクとその軽減策  .....................  44 \\n1) ライセンスに関するリスク  ................................ .. 45 \\n2) 調達容易性に関するリスク  ................................ .. 45 \\n3) 機密性に関するリスク  ................................ ...... 45 \\n4) アップデート対応に関 するリスク  ............................  45 \\n5) ベンダーロックインに関するリスク  ..........................  46 \\n７.３ テキスト生成 AIの機械学習モデルが直接提供されるケースに関する\\nリスクとその軽減策  ................................ ...............  48 \\n1) ライセンスに関するリスク  ................................ .. 48 \\n2) 調達容易性に関するリスク  ................................ .. 49 \\n3) 機密性に関するリスク  ................................ ...... 49 \\n4) アップデート対応に関するリスク  ............................  49 \\n5) ベンダーロックインに関するリスク  ..........................  49 \\n6) コストマネジメントに関するリスク  ..........................  49 \\n８ 従来型の情報検索サービスをテキスト生成 AIにより改善する手法  ... 50 \\n９ 文章間の類似性の機械的評価方法について  ........................  55', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 5}), Document(page_content='4 １ はじめに  \\nテキスト生成 AIの利活用について社会的期待が高まる一方で、その様々なリ\\nスク（運用リスク、情報セキュリティ、プライバシー侵害やリーガルリスク等）\\nへの対応もその重要性が高まっている。その中でもテキスト生成 AI利活用時の\\n情報セキュリティに関する検証項目の多くは既存の情報システムや AIシステム\\nと共通するが、一方でテキスト生成 AI固有と思われるリスクも存在する。この\\nテキスト生成 AI固有のリスクは、そのテキスト生成 AIのサービスの提供形態\\nやユースケースに特異な場合もあり一概に議論することは困難である。  \\n本文書は、 AI事業者ガイドライン（第 1.0版）（以降、 AI事業者ガイドライ\\nンと称する）およびその 別添（以降、別添と称する）を前提に、 DS-120 デジ\\nタル・ガバメント推進標準ガイドライン実践ガイドブック （以降、実践ガイド\\nブックと称する）への対応と実務上必要と思われる具体的なリスク軽減策につ\\nいて紹介する。重複 した記述を出来る限り避けるために引用を多めにした構成\\nにしたため、手元に AI事業者ガイドライン、別添と実践ガイドブックを用意\\nしてから読み進めてほしい。この構成は、テキスト生成 AIを政府情報システ\\nムへの利活用を計画しているシステム管理者にとって参照しやすい実践的な内\\n容になると考えている。  \\nこれらのリスクについての議論やその軽減策の方法論については、世間的に\\nも発展途上のものである点を留意いただきたい。  \\n１.１ 目的とスコープ  \\n \\n本文書は、テキスト生成 AIを活用した政府情報システムの開発及び業務改善\\nに従事する関係者に対し て、想定されるリスクの内、テキスト生成 AI固有と考\\nえられるリスクを特定し、そのリスクに対する軽減策の一般論を示すことを主\\nな目的としている。  \\nテキスト生成 AIを活用したプロジェクトのステークホルダー全体は、 機械学\\n習品質マネジメントガイドライン  第 4 版 Annex (2,3ページ)によると以下の\\n表のように分類される。  \\n \\nステークホルダ\\nーの種別  役割 \\n基盤モデル開発\\n者 基盤モデルの訓練を行う。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 6}), Document(page_content='5 サービス開発者  訓練済み基盤モデルを調整し、また、目的のタスクを基盤モデルが実行す\\nるよう誘導するプロンプトを装備することにより、目的とする用途向けのサービ\\nスを開発する。  \\nサービス提供者  目的とする用途向けのサービスを運用する。  \\nサービス利用者  上記サービスの直接利用者である。サービス利用者には個人と組織があ\\nる。組織の場合には組織内で使う場合と顧客向けに使う場合がある。  \\nサービス利用者\\nである組織の顧客  直接または間接にサービスを利用することがある（サービスを組織が個別\\nの顧客向けに使う場合など）。  \\nサービスを利用\\nしない一般市民  サービス利用者やその顧客の行動によって影響を受けることがある。  \\n行政等のガバナ\\nンス機関  サービスの社会的な影響を制御する（予防、軽減を図る、  監視する、被害\\nを補償する等）。  \\n表１ 機械学習品質マネジメントガイドライン  第 4 版 Annex での生成 AIのステ\\nークホルダーの識別表  \\n \\n本文章はこの分類 表の定義に従う。本文章の想定読者の役割は、 (1) 訓練済\\nみ基盤モデルを調整し、また、目的のタスクを基盤モデルが実行するよう誘導\\nするプロンプトを装備することにより、目的とする用途向けのサービスを開発\\nする、と(2)目的とする用途向けのサービスを運用する 、を実施もしくは委託\\nするサービス開発者とサービス提供者の２つである。本文章では基盤モデル開\\n発者や行政等のガバナンス機関等の役割は想定していない。なお、 この役割と\\nAI事業者ガイドライン (5ページ)での分類との関係は、サービス開発者は AI開\\n発者の一部と AI提供者、サービス提供者は AI利用者に対応されると みなせる 。 \\n本文書で言及されるリスクは、 2023年度までにデジタル庁で行われた行政で\\nのテキスト生成 AIの利活用の検証時に考察されたユースケースを元に想定され\\nており、テキスト生成 AI全般を網羅したものではない点に注意いただきたい。\\nこの検証については、 デジタル庁ホームページでの報告書 とその報告 書を解説\\nしたデジタル庁 Tech note に詳細が書かれている。  \\n本文書の利用は、テキスト生成 AIの利活用を計画しているシステム管理者が、\\n自身のユースケースに応じた想定リスクとその軽減策を参考に、テキスト生成\\nAIに固有のリスクを考慮したリスクマネジメントの実施を想定している。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 7}), Document(page_content='6 １.２ 本文書で想定するテキスト生成 AIの利活用方法  \\n \\n本文書ではテキスト生成 AIを以下の 4つのユースケースを想定している。  \\n \\n➢ ユースケース 1. チャットインターフェースで サービス 利用者とインタ\\nラクティブに対話する機能としてテキスト生成 AIをオンライン処理で用\\nいる \\n➢ ユースケース 2. 大量の文章に対してラベル付けやテキストデータ変換、\\nその他翻訳や要約や文章作成等の自然言語処理を行う機能としてテキス\\nト生成AIをバッチ処理で用いる  \\n➢ ユースケース 3. 情報検索を目的としたサービスで検索エンジンの補助\\nとしてテキスト生成 AIをオンライン処理で用いる  \\n➢ ユースケース 4. ダッシュボードやソースコード等を サービス 利用者の\\n自然言語により記述可能にする機能としてテキスト生成 AIをオンライン\\n処理で用いる  \\n \\nテキスト生成 AIの利活用でもっとも有名な OpenAI社のChatGPT はこの類型\\nではユースケース 1に該当する。テキスト生成 AIの利活用はチャット利用に限\\n定されない。  \\nユースケース 2の一例は ２.２ ２） パブリックコメントの返答作成業務\\nにテキスト生成 AIを適切に利活用するユースケース で詳細に述べる。  \\nユースケース 3の一例は ２．２  １） 情報検索サービスを国民向けに展開\\nする事例でテキスト生成 AIを適切に利活用する方法 で詳細に述べる。  \\nユースケース 4の一例は ２．２  ４） 信頼できるデータベースと連携して\\nテキスト生成 AIを適切に利活用するユースケース で詳細に述べる。  \\n１.３ 本書の構成  \\n \\n本文書は実践ガイドブックをベースにし、そこに対してテキスト生成 AI固有\\nのリスクや留意点を補足することを目指している。そこで、 「第３編第１章  実\\n践ガイドブックの構成  Point.2 チェックリスト」の分類にならい、新サービ\\nス企画時、予算要求前、調達実施前、設計・開発時、サービス実施時の段階で\\n検討すべきテキスト生成 AI固有のリスクとその軽減策を述べる。  \\n１.４ 用語', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 8}), Document(page_content='7 用語 解説 \\n生成AI 出力が単一の数値やラベルではなく、文章や画像や音声や動画といっ\\nた従来は人間が創作していた類のものを出力する機械学習モデルを使っ\\nたシステムのことを総称したもの。  \\nテキスト生成\\nAI 生成AIのうち、出力が文章に代表されるテキストのもの。出力は文章\\n以外でもソースコード等やテキストデータの形式を変換したものといっ\\nた自然言語以外の出力や、文章分類や固有表現抽出等といった従来の自\\n然言語処理課題を行うことも可能である。  \\n大規模言語モ\\nデル 昨今のテキスト生成 AIの背後にいることの多いニューラルネットワー\\nク型の機械学習モ デルの一種で、膨大なパラメータ数と膨大なテキスト\\nにより学習されていることが特徴の一つ。  \\nテキスト生成 AIの背後は必ずしも大規模言語モデルではない（機械翻\\n訳でのLSTM等）点や、大規模言語モデルの小型化研究が盛んであり必ず\\nしも「大規模」とは限らない点が混乱しやすい。  \\nプロンプト  大規模言語モデルへ入力するテキストデータのこと。  \\n膨大なテキストによる教師なし学習を事前学習とよび、特定の課題（下\\n流タスクとも呼ぶ）に特化させた事後学習 (ファインチューニング )とよ\\nぶ。以前はこの事後学習によりさまざまな自然言語処理課題に対応させ\\nる手法が主流だったが、大規模言語モデルではプロンプトによる指示を\\n変えるだけでさまざまな自然言語処理課題に対応することが可能になっ\\nた。 \\nトークン  自然言語を機械学習モデル等のシステムに扱いやすい単位で分割した\\nもの。日本語の場合、検索エンジンへは n-gramや形態素といった単位で\\nトークンが作られることが多く、大規模言語 モデルへはサブワードとい\\nったさらに細かい分割が一般に行われる。  \\n表２ 本文書の用語集', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 9}), Document(page_content='8 ２ 新サービス企画時のテキスト生成 AI固有の留意  \\n \\n本章では、テキスト生成 AIの新たなサービス企画時における利活用の適切性\\nを評価し、その結果生じうるリスクを特定し、これらのリスクに対する軽減策\\nを提供することを目的とする。具体的には、不適切な利活用事例と効果的な利\\n活用事例を識別し、政府情報システムにおけるテキスト生成 AIの適用可能性を\\n探る中で明らかにしていく。この章のスコープは、実際のサービス企画段階で\\nのリスク評価と、それに基づいた意思決定支援に焦点を当てている。  \\n２.１ テキスト生成 AIの利活用が不適切であるケースにテキスト生成 AI\\nを用いるリスク  \\n \\nテキスト生成 AIの利活用が不適切である場合にテキスト生成 AIを用いるこ\\nとによりリスクが発生することが考えられる。例えば以下の 6類型が考えられ\\nる。 \\n(1) テキスト生成 AIによる回答の期待品質が高すぎる場合  \\n(2) そもそも人間が行うべき仕事であり、 AIによる代替が不適切な場合  \\n(3) 特定の資格を必要とする作業であることが法令に定められている場合  \\n(4) テキスト生成 AIの知識に無い事項を答えさせる場合  \\n(5) テキスト生成 AI利活用の構築・運用費が費用対効果に見合わ ない場合  \\n(6) その他、 AI事業者ガイドラインの「共通指針」 (ページ12~20)に違反す\\nる場合 \\n \\n(1)は例えば、ユースケース 1のチャットインターフェース型のサービスを国\\n民向けに展開し、質問内容やサービスの期待値を特定のドメインに限定しない\\n場合に発生しやすい (組織の見解と異なる発言や、差別的言動や虚偽の情報な\\nどの不適切発言を行う等 )。チャットインターフェース上で AIが回答するサー\\nビスを行政が行う場合、規約等に十分記載したとしても、国民からの期待値を\\n限定させることが難しいと考えられるため、国民向けに広くユースケース 1を\\n展開することは難しいと考えられる。  \\n(2)は例えば、パブリックコメントの返答をテキスト生成 AIで全自動化する\\nケースは不適切な事例である。これはパブリックコメントの本来の目的は国民\\nからの質問に回答することではなく、広く国民の声を行政に届けることが目的\\nであるため、行政職員がパブリックコメントを読み込むことが本質であるから\\nである。  \\n(3)は例えば、症状についての記述から必要な薬をテキスト生成 AIに推定さ', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 10}), Document(page_content='9 せ、薬の処方箋を自動発行するケースは不適切な事例である。医師法や歯科医\\n師法に違反する。  \\n(4)はテキスト生成 AIの学習データに無い情報を聞いた場合に確実に発生す\\nる。例えば、デジタル庁 AI班の職員数をテキスト生成 AIに聞いた場合、根拠\\nのない事実と異なる適当な人数を回答することがある。これはテキスト生成 AI\\nの幻覚（ハルシネーション）と呼ばれる現象で、不適切な利活用例である。テ\\nキスト生成 AIの学習データに仮に情報があったとしても大規模言語モデルがそ\\nれを知識として確実に学習できるとは限らない点にも注意。  \\n(5)はテキスト生成 AIの利活用形態にも依存する。 ３ 予算要求前時のテキ\\nスト生成 AI固有の留意点 の箇所で述べる。特に方法 1のテキスト生成 AIをオ\\nンライン処理で用いる場合はリクエストあたりの運用費用が通常のシステムと\\n比べて高くなる傾向がある。  \\n(6)は具体的には AI事業者ガイドラインの本文の他、別添の各部ごとの「 「共\\n通指針」の解説」を参照していただきたい。例えばアイデア出しを特定の大規\\n模言語モデルに過度に依存した場合、得られるアイデアがその大規模言語モデ\\nルのバイアスに影響を受 けてしまう危険性がある。ただし、この問題は大規模\\n言語モデル固有ではなく、例えば内部職員や外部有識者の意見でも様々な種類\\nのバイアスが存在するため、同様に注意が必要である。  \\nこれらの事例は、そのままの形ではテキスト生成 AIの利活用が不適切になっ\\nてしまうが適切な工夫を行うことでテキスト生成 AIを有用に扱うことができる。\\nこれを次節で述べる。  \\n２.２ テキスト生成 AIの利活用が効果的なケースを見落とすリスク  \\n \\n前節の２．１  テキスト生成 AIの利活用が不適切であるケースにテキスト\\n生成AIを用いるリスク で挙げた (1)(2)(3)(4) の事例では工夫次第ではテキス\\nト生成AI利活用により政府情報システムや業務を改善することができる。  \\n1) 情報検索サービスを国民向けに展開する事例でテキスト生成 AIを適切\\nに利活用するユースケース  \\n \\nこの事例では、まず サービス利用者 に本当に提供したいものがユースケース\\n1のチャットインターフェースなのか、ユースケース 3の情報検索を目的とし\\nたサービスに生成 AIを活用したものなのかの検討を行う。おそらくほとんどの\\n場合は国民向けに利便性の高い情報検索サービスを提供したい、つまりユース\\nケース3になるだろう。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 11}), Document(page_content='10 ここでは、情報検索サービスにテキスト生成 AIを利活用する方法の一例を、\\n旧来の利便性のあまり高くないチャットボット型のサービスと比較して述べる。  \\n旧来の利便性のあまり高くないチャットボット型サービスの典型的な挙動は\\n以下である。  \\n➢ チャットボット が潜在的に返すことのできる回答候補の数が少なく、必\\n要とする回答 をサービス利用者 がどんなに入力しても得られない  \\n➢ サービス利用者 に文章で入力させるが、文中の単語の一部を抽出するだ\\nけで文意は無視される。また単語で検索されるが単語の表記揺れなどは\\n考慮されない。  \\n➢ チャットボットから返された検索結果の内容の理解に困難を伴い、関連\\nが低い回答内容を読解するための サービス利用者 への負荷が高い。  \\nこれらの課題は情報検索システムを中心とすると下記のように図示できる。  \\n \\n \\n図１ 情報検索システムでユーザビリティ向上を生成 AIで実現できる箇所  \\n \\nこれらすべての箇所でテキスト生成 AIは旧来のチャットボット型サービスあ\\nるいは検索システムを改善できる。詳細は ８ 従来型の情報検索サービスをテ\\nキスト生成 AIにより改善する手法 で述べる。  \\nテキスト生成 AIによる国民向けへの質の高い情報検索サービスの構築には、\\nいわゆる ChatGPTのようなユースケース 1に限らず、ユースケース 3の旧来の\\n情報検索システムの考え方を前提にしたテキスト生成 AIによる利便性の向上に\\nも検討の価値がある。特にこの手法の優位点は事前に準備した回答候補をベー\\nスとするため原理的には事前にすべての回答パターンをテストできるため高い\\n品質要件を満たすことができる点である。また、テキスト生成 AIを主にバッチ\\n処理で用いることでコスト予測が立てやすいため予算要求前での見積もり精度\\nを上げることもできる。こちらは ５．２  ４） テスト済みの生成物のみを用\\nいる場合の工夫 でも詳細に述べる。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 12}), Document(page_content='11 2) パブリックコメントの返答作成業務にテキスト生成 AIを適切に 利活用\\nするユースケース  \\n \\nパブリックコメントの返答作成業務は行政職員が各パブリックコメントを読\\nみ込むことにその意義がある。しかしパブリックコメントが大量に届いた場合\\nに、限られた職員数で限られた時間内にパブリックコメント内に含まれる意見\\nを全て拾い上げることが現実的に厳しい場合が存在する。その際に例えば以下\\nのような方法でテキスト生成 AIを用いることで、職員によるパブリックコメン\\nトからの意見抽出の品質を向上できる可能性が高い。  \\n(1) 職員がパブリックコメントの全量を確認し、意見内容の類型化を行う  \\n(2) ひとつのコメントに複数の内容が含まれることも多い ため、テキスト生\\n成AIを用いてコメントを内容単位で分割する  \\n(3) 分割したコメント内容をテキスト生成 AIにより類型化したラベル付けを\\n行う \\n(4) ラベルごとに職員が妥当なラベル付けであるかを確認する  \\n(5) 類型化したラベルがつけられなかったコメントは見落とした意見である\\n可能性が高いため職員が改めて精読する  \\n(5)の工程があることで (1)の作業に過度の無謬性を必ずしも求めなくて良く\\nなるため職員の精神的負担も軽減されると考えられる。また (4)の工程は職員\\nが行う手間が純増する箇所ではあるが、文のラベル付の妥当性判断は文から自\\n身でラベル付するよりもだいぶ負担が少ないため相対的に時間をかけずに行う\\nことができる。  \\n3) 法令で決められた資格保有者等の支援についてテキスト生成 AIを適切\\nに利活用するユースケース  \\n薬の処方箋と医師のように、業務の中には資格をもった従事者が必須とされ\\nるものがある。この場合、医師をテキスト生成 AIで代替することは不可能であ\\nるが、医師をテキスト生成 AIでサポートする方法は考えられる。例えば、薬の\\n処方箋の原案を何パターンかテキスト生成 AIが医師へ提案し、医師自身がその\\n中で妥当なものがあれば一番良いものを選ぶ、といった形で医師の業務支援を\\n行うといった方法が考えられる。  \\nこれはあくまでわかりやすさを重視した一例であって、実際には資格保有者\\nの業務をちゃんと理解した上で必要な支援を検討することが必要である。業務\\nの現状把握の重要性については実践ガイドブックでも述べられている  \\n4) 信頼できるデータベースと連携してテキスト 生成AIを適切に利 活用す', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 13}), Document(page_content='12 るユースケース  \\n \\n不適切な例に挙げた「デジタル庁 AI班の職員数」についての回答は、デジタ\\nル庁の人事情報が含まれるデータベースに対して適切なデータベースへの問い\\n合わせ（クエリ）文を発行することで正確な数字が得られる。ここのクエリ発\\n行にテキスト生成 AIを利活用することで、自然な文章での入力から正確な回答\\nが得られるシステムを構築することができる。このような生成 AIの活用方法は、\\nダッシュボードに組み込まれた製品として利活用することも可能である。製品\\n利用の場合も、特別に開発する場合も、データベ ースのテーブルやカラムの定\\n義をテキスト生成 AIに与えないと正確なクエリ文生成ができない点には注意が\\n必要である。  \\n２.３ 技術的実現可能性の検討によるリスク軽減  \\n \\n前節の２．２  テキスト生成 AIの利活用が効果的なケースを見落とすリス\\nクで挙げた活用事例はあくまで机上の話であり、実際に技術的に実現可能かは\\n個別具体のユースケースやデータに依存するため確かなこと は言えない。最悪\\nの場合、調達後に技術的実現可能性がなかったことが判明するリスクもありう\\nる。 \\nテキスト生成 AIの重要な特徴のひとつにプロンプトの変更だけで多様なユー\\nスケースに対応できるというものがある。この特徴を使えば AIの専門家でなく\\nても、テキスト生成 AIでどのようなことができそうかを事業者に頼らずに検討\\nすることが可能である。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 14}), Document(page_content='13 例えば、情報検索システムにテキスト生成 AIを組み込む場合は、自然文から\\nの意図推定を指定したフォーマットで十分な精度で実施できそうかを下記のよ\\nうなプロンプトで検討できる。  \\n \\nテキスト生成 AIへの入力例  \\n下記の「ネコに国政選挙の選挙権を与える政策」に対するコメントから「賛成か否\\n(is_agree) 」「提言 (suggestion) 」をjson形式で抽出する  \\n \\n \\n# コメント  \\n子どもに選挙権がないのに猫に選挙権を与えることはいかがなものかと思う。せめて子猫\\nには選挙権与えないといった猫の中での対応が必要  \\n \\n# output format  \\n{ \\n  \"is_agree\": ture|false,  \\n  \"suggestion\": \"{#text}\"  \\n} \\n \\nテキスト生成 AIからの出力例  \\n{ \\n \"is_agree\": false,  \\n \"suggestion\": \" 猫の中での対応が必要 \" \\n} \\n \\n図２ テキスト生成 AIで出力形式を json形式に指定した例。この例での生\\n成物のjsonの内のsuggstion だけを最終的な出力としてサービス利用者に返\\nすことで、プロンプトインジェクションにもより頑健になる（絶対ではない点\\nに注意）。本例では Swallow-70b-instruct -hfを利用した。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 15}), Document(page_content='14 ラベリング課題でどのくらいの精度が出せそうかについては下記のようなプ\\nロンプトで検討することができる。  \\nテキスト生成 AIへの入力例  \\n下記のコメントが「ネコに国政選挙の選挙権を与える政策」に対して賛成か反対かを判定\\nせよ \\n \\n# コメント  \\n子どもに選挙権がないのに猫に選挙権を与えることはいかがなものかと思う。せめて子猫\\nには選挙権与えないといった猫の中での対応が必要  \\n \\n# output format  \\n{賛成|反対} \\n \\nテキスト生成 AIからの出力例  \\n反対 \\n図３ テキスト生成 AIでラベリング課題を実施させた例。本例では Swallow-\\n70b-instruct -hfを利用した。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 16}), Document(page_content='15 候補出し課題でどのくらいの精度が出せそうかについては下記のようなプロ\\nンプトで検討することができる。  \\n \\nテキスト生成 AIへの入力例  \\n「ネコに国政選挙の選挙権を与える政策」に対する賛成意見と反対意見を 3つずつ作って  \\n \\nテキスト生成 AIからの出力例  \\nはい!「ネコに国政選挙の選挙権を与える政策」に対する賛成意見と反対意見を 3つずつ\\n作りました。  \\n \\n●賛成意見  \\n・猫が国政選挙に参加できるようになることで、多様な意見や価値観が反映され、より公正\\nかつ民主的な政治システムが実現される可能性がある。  \\n・猫が国政選挙に参加することで、人間だけでなく動物にも配慮した社会づくりが進む可能\\n性がある。  \\n・猫が国政選挙に参加することで、政治への関心が高まり、投票率が上がる可能性があ\\nる。 \\n \\n●反対意見  \\n・猫が国政選挙に参加することで、人間と同じ権利を持つことになり、法律上の問題が生じ\\nる可能性がある。  \\n・猫が国政選挙に参加することで、猫の福祉や健康面に悪影響を及ぼす可能性がある。  \\n・猫が国政選挙に参加することで、猫に対する偏見や差別が助長される可能性がある。  \\n \\n図４ テキスト生成 AIで文章を作成させた例。本例では Swallow-70b-\\ninstruct -hfを利用した。  \\n \\nこれらのプロンプトは非常に簡素なものだが、今回の課題がどのくらい難し\\nいものなのかについては実際の想定データや出力形式をプロンプトに入れた検\\n討ができることを示している。  \\nこの時点である程度、事業者ガイドラインの「共通指針」の中の「人間中心」\\nの要件を満たせそうか、どのように確認すべきか、どこまでを目標をするかに\\nついて検討も行えると良い。具体的手法は別添 (ページ130等)にも記載されて\\nいるが、より具体的なテストケースをどのように どこまで作るべきか 、はプロ\\nジェクトの性質にも依存するため一概に決定することは困難である。傾向とし\\nて、テキスト生成 AIにもたせる役割を明確にした方が必要なテストケース数を', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 17}), Document(page_content='16 削減でき、テスト観点も明確にできる。特にユースケース 1では(1)テキスト生\\n成AIが回答するテーマを明確にする (2)そのテーマ以外では回答させない、と\\nいった工夫を行わないと、テストケースが絞り込めず莫大になってしまい、開\\n発したシステムが十分な品質かの確認が非現実的になってしまう。  \\n実際に十分な品質要件が達成できるかについては開発時のテストで確認 する\\n必要がある。詳細は ５ 設計・開発時のテキスト生成 AI固有の留意点 の節で\\n述べる。  \\n大規模言語モデルの種類によっては課題によって精度が異なることが想定さ\\nれる。さらに一部の大規模言語モデルでしか検討できないことにより、次節で\\n述べる提供形態の選択肢の自由度が狭まりベンダーロックインのリスクも高ま\\nるため、職員が複数の大規模言語モデルに対して検討できる状態が望ましい。\\n大規模言語モデルは既存のテキストデータだけから学習させるだけでなく、\\n「どのような回答が望ましいか」について人間がラベル付けしたデータに基づ\\nいた追加学習が行われていることが多い。この「回答の望ましさ」については\\n基盤モデル開発者やサービス 開発者の方で決められており、この「望ましさ」\\nの違いが、ユースケースによっては大規模言語モデルの選定の考慮事項になる。\\n（参考: OpenAI 社が公開している「望ましさ」について。 How should AI \\nsystems behave, and who should decide? ） \\n多くの大規模言語モデル ではいくつかの制限はあるものの、無料で試用でき\\nるWebサービスが用意されていることがあり、それを用いての検討を行えば、\\n期待品質を満たさない手戻りリスクを軽減することができる。  \\n２.４ 民間サービスの活用  \\nテキスト生成 AIを利活用するための提供形態は大きく以下の３つに類型でき\\nる。 \\n(1) テキスト生成 AIを組み込んだサービスとして提供されるケース  \\n(2) テキスト生成 AIを利用するための Web API がクラウドサービスとして提\\n供されるケース  \\n(3) テキスト生成 AIの機械学習モデルが直接提供されるケース  \\n(1)はSaaSサービスとして提供 されることが多い。 (3)はクラウドサービスや\\nオンプレミスでサーバを調達して機械学習モデルをデプロイして使うケースを\\n想定している。 「自分で作りすぎない」 「クラウド・バイ・デフォルトの原則」\\nから(1), (2), (3) の順番での検討を推奨する。必須要件へのカスタマイズ性や\\n取り扱う情報の機密性の高さから (1)や(2)よりも(3)を合理的に選択するケー\\nスも十分にありうるため、企画の内容に応じて精査を推奨する。この選択に利\\n用できる実践的なフレームワークやチェックリストは現時点 (2024年6月現在)', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 18}), Document(page_content='17 で開発できていない ため、ここでは留意点の紹介に留まる。  \\n \\n提供形態  開発コスト  カスタマイズ性  運用コスト  \\nテキスト生\\n成AIを組み\\n込んだサービ\\nスとして提供\\nされるケース  既にあるものを利用\\nするため基本的には無\\nい \\n既存の情報システム\\nにテキスト生成 AIを組\\nみ込む場合は選択肢に\\n挙がらない  基本的には低い。サービ\\nス提供元会社と直接委託契\\n約を結び、こちらの要望を\\n積極的に取り入れる場合\\nは、カスタマイズ性も高くな\\nる  サービス利用料程度し\\nかかからず、既に利用マニ\\nュアルやヘルプデスクが準\\n備されている場合もあり  \\nテキスト生\\n成AIを利用\\nするための\\nWeb API が\\nクラウドサー\\nビスとして提\\n供されるケー\\nス Web API を経由でテ\\nキスト生成 AIを利用す\\nるだけであれば開発コ\\nストは少ない  \\n既存の情報システム\\nにテキスト生成 AIを組\\nみ込む場合はプロンプ\\nトの試行錯誤やテスト\\n工数が通常のシステム\\n開発と比べて大きい  さまざまな種類の大規模\\n言語モデルが主要なクラウ\\nドサービスによって Web \\nAPI形式で提供されてい\\nる。独自に学習した大規模\\n言語モデルを使うオプション\\nもあり、テキスト生成 AI部\\n分のカスタマイズ性は最も\\n高い 入出力のトークン数や文\\n字数に比例する料金形態\\nをとっていることが多く、コ\\nスト試算が独特になる。利\\n用する大規模言語モデル\\nによって価格が大きく異な\\nるため、品質要求と運用コ\\nストのバランスが求められ\\nる \\nテキスト生\\n成AIの機械\\n学習モデルが\\n直接提供され\\nるケース  オンプレミスでのサー\\nバ調達やクラウド上で\\nの計算環境を用意し、\\nその上にテキスト生成\\nAIを利用するための開\\n発が必要になるため、\\n開発コストは最も 高い 利用できる大規模モデル\\nに制約がかかり、最高峰の\\n大規模言語モデルが利用\\nできない可能性が高い  \\nインターネットを利用しな\\nくても良いので、ネットワー\\nク要件やセキュリティ要件に\\n応じたカスタマイズ性は最も\\n高い ハードウェアのメンテナ\\nンスやメモリ管理などでや\\nらなければならないことが\\n多いため、 3つの中では最\\nも運用コストが高い傾向が\\nある \\nただし潤沢な計算リソー\\nスが確保でき、テキスト生\\n成AIの利用頻度が非常に\\n多い場合に、最も運用コス\\nトが抑えられる可能性もゼ\\nロでは無い。  \\n大規模言語モデルの小\\n型化も盛んに研究されてい', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 19}), Document(page_content='18 るため、将来的には現実的\\nなコストで収まる可能性は\\n高い \\n表３ テキスト生成 AIの提供形態による違いを簡単にまとめたもの  \\n \\n提供形態ごとに考慮すべきリスクを、ライセンス、調達容易性、機密性、ア\\nップデート対応、ベンダーロックイン、コストマネジメントの 6観点で整理し\\nたものを付録の ７ 提供形態ごとの想定リスク にまとめたため、そちらも参照\\nいただきたい。  \\n２.５ ２章のまとめ  \\n \\n新サービス企画時には、テキスト生成 AIの利活用が不適切であるケースと効\\n果的なケースを見極めることが重要である。本章では、適切な工夫によってリ\\nスクを軽減し、テキスト生成 AIを有効活用する例を示した。実際のユースケー\\nスに応じた想定リスクとその軽減策が、サービスの質を高め、不測の問題を未\\n然に防ぐための知見となることを目指している。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 20}), Document(page_content='19  \\n３ 予算要求前時のテキスト生成 AI固有の留意点  \\n \\n予算要求前におけるテキスト生成 AIのリスクと機会の評価を目的とした本章\\nでは、異なる提供形態に応じた予算策定のための考慮点を提供する 。予算計画\\nの精度を高めるために、コスト削減の観点からの実用的な留意点と、適切な提\\n供形態を選択するための留意点を挙げる。スコープは、テキスト生成 AIを活用\\nする際の財務的なリスク管理と、資源配分の最適化に重点を置いている。  \\nテキスト生成 AIを利用するための提供形態の違いにより、必要な予算の金額\\nが大きく異なるため、予算要求前に提供形態の目途をつけるべきである。適切\\nな提供形態の選択に失敗すると、予算の大幅な超過あるいはその逆が発生する\\nリスクが大きい。このリスクは各利用形態の特徴を把握し、利用形態ごとに適\\n切なコスト削 減に向けた検討を行うことによって軽減できる。ここでは、提供\\n形態ごとに留意すべき点を述べる。  \\nどのケースでも事業者ガイドラインと別添の「第２部  AI により目指すべき\\n社会及び各主体が取り組む事項」と「第 5部 AI利用者に関する事項」を参照\\nしていただきたい。テキスト生成 AIを利用するための Web APIがクラウドサー\\nビスとして提供されるケースとテキスト生成 AIの機械学習モデルが直接提供さ\\nれるケースの場合は、 「第 4部 AI提供者に関する事項」と、必要に応じて「第\\n3部 AI開発者に関する事項」も参照していただきたい  \\n３.１ コスト削減に向けた検討  \\n1) ハードウェア・ソフトウェアのコスト削減観点  \\nア テキスト生成 AIを組み込んだサービスとして提供されるケース  \\n類似サービスの価格を調べ、市場の相場と比べて高価すぎないかの確認を行\\nう。 \\nイ テキスト生成 AIを利用するための Web API がクラウドサービスとし\\nて提供されるケース  \\n性能が良いとされる大規模言語モデルほど、リクエストあたりの費用が高く\\nなる傾向にある。また、リソースが共有される汎用的な基盤モデルの利用より\\nも、再学習を行った 独自の大規模モデル の利用の方が 、費用が高くなる場合が\\n多い。テキスト生成 AIの生成物の品質目標を定め、事前にどのくらいの性能の\\n大規模言語モデルで十分かの検討を行う。ただし、実際に開発が進むにつれて', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 21}), Document(page_content='20 当初想定した大規模言語モデルでは性能不十分であることが発覚するリスクも\\n十分考えられる点にも注意する。  \\nまた、回答精度を上げるためにプロンプトへの記述を手厚くするほ ど、トー\\nクン数や入力文字数に比例し費用が高くなるため、プロンプトの改良による精\\n度改善の試行錯誤により初期検討時のプロンプトよりも費用が高くなる可能性\\nも十分考えられる。想定よりもリクエスト数が多い場合に想定以上の費用が高\\nくなる可能性もある。  \\nこの場合、初期検討時のものと比べてどこまで費用が上振れするものかのデ\\nータがまだないため、妥当な見積もり方法が確立していない点に注意が必要。  \\nクラウドサービスによっては従量課金でなく定額プランを用意している場合\\nもあるが、定額プランは一般的にかなり高価である。しっかりと見積も りをし\\nたうえで採用することを強く推奨する。  \\nウ テキスト生成 AIの機械学習モデルが直接提供されるケース  \\n多くのケースで最もコストが高い選択肢になる傾向がある。少なくてもハー\\nドウェアの調達から必要な場合は、初期投資が最も高い。他の利用形態で要件\\nを十分満たすかの検討とコスト試算を行ったうえで、この利用形態を採用する\\nかを検討する。  \\n2) アプリケーションのコスト削減観点  \\nア  テキスト生成 AIを組み込んだサービスとして提供されるケース  \\nテキスト生成 AIで扱われる大規模言語モデルは、ひとつのモデルだけで多様\\nな自然言語処理（ 例えば、翻訳や要約、文章作成や固有表現抽出等）が可能で\\nある。この特徴から、バラバラに実装・提供されていた複数の自然言語処理関\\n連の機能や製品をまとめられないかの検討をし、重複投資を避ける。  \\nイ テキスト生成 AIを利活用するための Web API がクラウドサービスと\\nして提供されるケース  \\n生成AIへのリクエスト 1件あたりの平均費用を下げるか、そもそもリクエス\\nト量を減らすことでコスト削減が可能である。平均費用の方は ３．１  １） \\nハードウェア ・ソフトウェアのコスト削減観点 で述べたため、ここでは生成\\nAIへのリクエスト量を減らすための検討事項を紹介する。  \\nリクエスト量を大幅に減らすことのできる選択肢として主なものは以下の 3\\nつである。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 22}), Document(page_content='21 a) 複数のリクエストを一つに集約する  \\nテキスト生成 AIのWeb APIへの複数リクエストを一つに集約すればコストカ\\nットにつながる可能性がある。ただしこの手法ではリクエスト 1件あたりの ト\\nークン数が多くなるため、リクエスト 1件あたりの 平均費用が高 くなり、結果\\nとしてコストカット効果に乏しい場合もある。また、 テキスト生成 AIにとって\\nの処理難易度が上がることで品質劣化を招く危険性もある。  \\nb) テキスト生成 AI以外の手法を採用する  \\n例えば、文中の単語 や特定の品詞を抽出するだけであれば形態素解析器で十\\n分であり、文間の意味的類似度を測るだけであればベクトル表現（ 埋め込み表\\n現、embeddingともいう ）の採用で十分な場合もある。このようにテキスト生\\n成AI以外の手法で十分な場合ではテキスト生成 AI以外の手法をまず検討すべ\\nきである。 またこれら の自然言語処理 手法は、テキスト生成 AIとの二者択一で\\nはなく、相互に 弱みを補完しながら組み合わせて利用することも十分に考えら\\nれる。  \\nc) 過去のテキスト生成 AIの生成物を再利用する  \\n過去にテキスト生成 AIで生成された実績のあるリクエストと同じようなリク\\nエスト（例えば リクエスト文字列を ベクトル表現 化し、それと近しいベクトル\\n表現の場合に、同じようなものとみなす ）の場合、キャッシュサーバー等から\\n過去の生成物を送信するようにし、テキスト生成 AIのWeb APIにリクエストを\\nさせない。この手法をより極端にした場合、テキスト生成 AIのWeb APIへのア\\nクセスは全て事前にバッチ処理で行い、テキスト生成 AI関連の処理にかかるコ\\nストを制御しやすくする手法も考えられる。この手法に関しては、 ５．２  ４） \\nテスト済みの生成物のみを用いる場合の工夫 で詳細に述べる  \\nウ テキスト生成 AIの機械学習モデルが直接提供されるケース  \\n大規模言語モデルの実行にともなう計算コストに直接影響される形でハード\\nウェアや運用に関連するコストが増加する。そのため大規模言語モデルの実行\\nにともなう計算コストが重要であり、その観点や手法は Web API 利用のケース\\nでの検討事項と同様である。  \\n3) 運用業務のコスト削減観点  \\nア テキスト生成 AIを組み込んだサービスとして提供されるケース  \\nアカウント管理に関連する業務コストは 無視できないほど大きい。これは新', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 23}), Document(page_content='22 規着任者だけではなく、異動者や退職者のアカウント管理も必要となり、組織\\n変更と同期が求められるからである。既に組織に紐づいた形でのアカウント管\\n理が導入されているならば、そのアカウントでの認証に用いられるシングルサ\\nインオンでアカウント管理の導入ができれば、アカウント管理業務のコストは\\n大幅に削減できる。例えば、ガバメントソリューションサービス（ GSS）の\\nMicrosoft Entra ID のシングルサインオンがそれに該当する。  \\nイ テキスト生成 AIを利用するための Web API がクラウドサービスとし\\nて提供されるケース  \\n一般的なシステム開発と大きな違いはないが、テキスト生成 AIの Web APIの\\nキャパシティプランニングが入出力のトークン数にも依存するといった特殊性\\nや標準的な Web API とくらべてレスポンスタイムが遅い（ ただし、高速化する\\n方向での開発も盛んである ）傾向にある。そのため、これらの指標についての\\nサービスレベルや監視の設定 に注意が必要である。テキスト生成 AIのWeb API\\nへの負荷を下げることができれば、これらの問題も軽減できる。この負荷を下\\nげる手法は ３．１  ２） アプリケーションのコスト削減観点 を参考にしてい\\nただきたい。  \\nウ テキスト生成 AIの機械学習モデルが直接提供されるケース  \\n一般的なシステム開発と大きな違いはないが、 GPUメモリが大規模言語モデ\\nルの出力トークン数の影響を強く受けるといったキャパシティプランニングに\\n特殊性がある 。そのため、これらの指標についてのサービスレベルや監視の設\\n定にも注意が必要である。この負荷を下げる手法は ３．１  ２） アプリケー\\nションのコスト削減観点 を参考にしていただきたい。  \\n4)その他のコスト削減観点  \\nア テキスト生成 AIを組み込んだサービスとして提供されるケース  \\nアカウント数に比例した価格体系であることも多く、本当に必要とする サー\\nビス利用者 のみアカウントを配布する。常駐 のヘルプデスクではなくマニュア\\nルや動画コンテンツでの解説等を採用する。ただしテキスト生成 AIを用いた業\\n務改善プロジェクトのような不確実性の高いプロジェクトの場合、本当に必要\\nとするかの見極めは難しく、潜在的な業務改善効果は高いがテキスト生成 AIに\\n不慣れな サービス利用者 のために手厚いサポートが重要であることも考えられ\\nるため、一般的な SaaS製品の導入と比べて検討が困難な傾向がある。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 24}), Document(page_content='23 イ テキスト生成 AIを利用するための Web API がクラウドサービスとし\\nて提供されるケース  \\nすでにテキスト生成 AIを利用したシステム がある場合、実績をベースにコス\\nト削減が可能かの検討を行う。例えば、定額プランを採用していた場合、実際\\nのアクセス数から従量課金に見直せないかの検討を行う等が考えられる。  \\nウ テキスト生成 AIの機械学習モデルが直接提供されるケース  \\nすでにテキスト生成 AIを利用したシステムがある場合、実績をベースにコス\\nト削減が可能かの検討を行う。例えば、機微な用途が限定されていたことから\\nセキュリティ要件を見直し、 Web API 形式の場合のコスト検討を行う等が考え\\nられる。  \\n３.２ ３章 まとめ \\n \\n予算要求前時には、選択された提供形態に応じて大幅に異なる予算規模を見\\n積もる必要がある。本章では、コスト削減を目指した各提供形態の留意点を詳\\n述し、AI事業者ガイドラインとの観点にマッピングしながら、実用的なリスク\\n軽減策を紹介しました。これらの対策が予算超過や不足を防ぎ、効率的なプロ\\nジェクト運営をサポートする一助となれば幸いである。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 25}), Document(page_content='24 ４ 調達実施前時のテキスト生成 AI固有の留意点  \\n \\n本章の目的は、調達実施前の段階で、テキスト生成 AIに関連する非機能要件\\nを明確にし、サービス実施時の品質保証を確立することである。 テキスト生成\\nAIの利活用を計画しているシステム管理者が、サービスの期待品質を具体的に\\n理解し、これを適切に盛り込んだ調達要件を作成できるようにすることをスコ\\nープとする。  \\n非機能要件の明確化をすることで、サービス実施時に問題が発覚することに\\nよるシステムが一般的に 期待される品質（非機能要件に該当しやすい）を満た\\nさなかった場合におきる 炎上リスク や開発手戻りリスクを軽減する。通常のシ\\nステム開発の非機能要件と比べて、テキスト生成 AIを用いたシステムの場合、\\nテキスト生成 AIの生成物に対するサービスの期待 品質や、 AI事業者ガイドラ\\nインで挙げられている「人間中心」 、 「安全性」 、 「公平性」 、 「プライバシー保\\n護」 、 「セキュリティ確保」 、 「透明性」 、 「教育・リテラシー」 、 「公正競争確保」 、\\n「イノベーション」の指針を考慮する。  \\nAI事業者ガイドラインでの指針では別添に具体的な手法が掲載されているた\\nめ、本章ではサービスの期待品質についての観点をユースケースごとに具体的\\nに考察を行う。  \\n４.１ チャットでの利用 の期待品質  \\n \\nここではユースケースのうち、 チャットインターフェースで利用者サービス\\n利用者とインタラクティブに 対話する機能としてテキスト生成 AIをオンライン\\n処理で用いるケース での期待品質について述べる。 理想的な応答のテストケー\\nスの量と質についての要件を決める。例えば、このシステムがゴミ出し方法の\\nルールについてのものであれば、ゴミの種類や捨て方の方法ごとに 10種類、全\\nく関係ない質問を 100種類作成し、その質問の 99%以上で妥当な回答を返すこ\\nとを要件にいれる。妥当かどうかの基準はできるかぎり明確にする。この基準\\nの明確化については ５．２  ２） 生成物の品質評価が困難であることに起因\\nするリスク で詳細にふれる。  \\nこの期待品質の基準が現実的なものか、は問題の難しさにも依存するため、\\n一概に決め切るのが難しく、その基準が妥当なものかの判断も非常に難しい。\\nしかし、期待品質を明確にしないと、期待品質を下回るシステムが納品される\\nリスクがある。軽減策として、この種のシステムを委託開発する場合は、プロ\\nポーザル型の調達方法を採用し、調達要件を作成するさいに複数の事業者に相\\n談することを推奨する。そのさいに事業者から回答された現実的な品質レベル', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 26}), Document(page_content='25 が受け入れにくいものであれば、まだ求めることに対して技術が追いついてい\\nないとみなし、プロジェク トの中止を考慮に入れた検討を推奨する。  \\n４.２ バッチ処理での利用 の期待品質  \\n \\nここではユースケースのうち、 大量の文章に対してラベル付けやテキストデ\\nータ変換、その他翻訳や要約や文章作成等の自然言語処理を行う機能としてテ\\nキスト生成 AIをバッチ処理で用いるケース での期待品質について述べる。 テス\\nトケースを充実させることで期待品質を満たすかの確認を要件に入れ、低品質\\nなシステム納品リスクの軽減ができる。このケースでは偽陽性・偽陰性のバラ\\nンスを考慮し、実用的な受け入れ基準を決めることが重要である。  \\n例えば、書類審査業務の代わ りをテキスト生成 AIで行う場合を考える。 まず\\nリスクを「本来は審査 NGとすべき書類を審査 OKとしてしまう（偽陽性） 」 「本\\n来は審査 OKとすべき書類を審査 NGとしてしまう（偽陰性） 」の２つに分けて整\\n理する。それぞれでどのくらいのミスが許容できるかを検討する。  \\n「本来は審査 NGとすべき書類を審査 OKとしてしまう（偽陽性） 」がそのまま\\nでは全く許容できない場合、テキスト生成 AIで審査OKとなった場合は必ず人\\n間でも審査する ことで軽減できる。この場合は (1)テキスト生成 AIに審査NGと\\n判定されたケースを人間が審 査しないことによる業務削減や、 (2)審査OKにし\\nた理由をテキスト生成 AIに作成させることによる審査過程の補助による改善効\\n果が見込ま れる。 \\n「本来は審査 OKとすべき書類を審査 NGとしてしまう（偽陰性） 」 がそのまま\\nでは許容できない場合、審査 NG理由をテキスト生成 AIで生成させ、その結果\\nを申請者にフィードバックし、 (1)修正し再提出してもらう (2)理由に納得いか\\nない場合に備え、テキスト生成 AIを介さず直接人間が審査する口を用意する、\\nといった方法をとればリスクが許容できるまで軽減できる可能性が高い。  \\nこれらの 方法を採用することで は人間による審査をゼロにはできす、テキス\\nト生成AIによる業務改善効果が限定化されてしまうが、 しかし、 全てを人間で\\n実施する場合と比べて、審査リードタイム（申請側にとってメリット）や審査\\n業務の負荷（審査側にとってメリット）の改善が期待できる。  \\nまた、ラベリングした結果が多少不正確でも許容できるユースケースの場合\\nは、サービス利用者 からのフィードバックを反映する仕組みを導入する等の運\\n用を始めてから改善していく、と割り切った考え方もできる。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 27}), Document(page_content='26 ４.３ 情報検索での利用 の期待品質  \\n \\nここではユースケースの うち、情報検索を目的としたサービスで検索エンジ\\nンの補助としてテキスト生成 AIをオンライン処理で用いるケース での期待品質\\nについて述べる。 テストケースを充実させることで期待品質を満たすかの確認\\nを要件に入れ、低品質なシステム納品リスクの軽減ができる。また、テキスト\\n生成AIをオンライン処理で用いることで、レスポンスタイムが大幅に悪化する\\nため、レスポンスタイムのサービスレベルの検討も必要になる。通常の情報検\\n索サービスではレスポンスタイムのサービスレベルが数秒以下に設定されるこ\\nとが多いが、テキスト生成 AIをオンライン処 理で用いた場合にこのサービスレ\\nベルが達成できない可能性がある。レスポンスタイムの悪化が許容できない場\\n合、テキスト生成 AIはバッチ処理のみの利用（ ５．２ ４） テスト済みの\\n生成物のみを用いる場合の工夫 も参照いただきたい）やテキスト生成 AI以外\\nの手法をうまく組み合わせる (８ 従来型の情報検索サービスをテキスト生成\\nAIにより改善する手法 も参照いただきたい )ことを検討する。  \\n期待品質を満たすかの基準としては、一般的な情報検索サービスと同様に、\\n再現率と適合率をわかりやすい受け入れ基準にすることができる。  \\n４.４ 自然言語からのプログラム作成での利用 の期待品質  \\n \\nここではユースケースのうち、 ダッシュボードやソースコード等をサービス\\n利用者の自然言語により記述可能にする機能としてテキスト生成 AIをオンライ\\nン処理で用いるケース についての期待品質を述べる。 これもテストケースの充\\n実をさせることで期待品質を満たすかの確認を要件に入れ、低品質なシステム\\n納品リスクの軽減ができる。ダッシュボードの数値だしの場合、問い合わせ文\\n章と人間が 実施した 場合に得られる正解の数字の対を何パターンか用意し 、ど\\nのくらいの正答率を基準にするか、で受け入れ基準を作成できる。 例えば、性\\n別・月ごとの区市町村の人口のデータベー スに接続したダッシュボードの場合、\\n「2024年１月の東京都の男性人口は？」 という問いに対し、あらかじめ集計し\\nた「6918630」という回答を用意し、この数字と同じものを出力できるか否か、\\nをテストする。  \\n４.５ ４章 まとめ \\n \\n調達実施前には、非機能要件を明確化し、サービス実施時の品質を保証する\\nことが不可欠である。本章では、ユースケースごとの期待品質を定め、プロジ', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 28}), Document(page_content='27 ェクトの品質目標を達成するための具体的な検討を示した。この段階での正確\\nな要件定義が、プロジェクトの成功において決定的な役割を果たすため、本検\\n討例が参考にな れば幸いである。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 29}), Document(page_content='28 ５ 設計・開発時のテキスト生成 AI固有の留意点  \\n \\n本章では、テキスト生成 AIの設計・開発時に特有のリスク及び品質評価の課\\n題に着目する。テキスト生成 AI固有の留意点として、生成物の品質向上と品質\\n評価が困難である点が挙げられるからである。そこで、本章の目的は、テキス\\nト生成AIを用いたシステムの開発において、生成物の品質を保証し、その評価\\nに関するリスクを軽減するための方法論を提供することである。スコープには、\\n生成物の品質向上のためのテスト戦略と、その品質評価プロセスの提案を含ん\\nでいる。  \\n設計時に留意すべき点は  ３．１  コスト削減に向けた検討 と４ 調達実施前\\n時のテキスト生成 AI固有の留意点 と重複するため割愛する。  \\n５.１ テキスト生成 AIの生成物の品質面への懸念  \\nテキスト生成 AIの生成物の品質を完全に保証することは困難である。ここで\\nは実際の生成物が十分な品質でなかった場合のリスクとその軽減策について述\\nべる。リスクの発生を予防する軽減策は、 ５．２  テキスト生成 AIによる生\\n成物の品質評価・品質保証についてのリスクとその軽減策 も参照にしていた\\nだきたい。  \\n1) テキスト生成 AIを分類やラベリングに利活用するケース  \\nテキスト生成 AIの生成物を文章として扱うのではなく、テキスト生成 AIで\\n分類やラベリング課題を解かせて、その結果を用いるケースで、その結果が不\\n適切であった場合の軽減策について述べる。  \\nこの問題は、テキスト生成 AI固有ではなく、従来の AI利活用の分類問題や\\n人間参加型 AI (Human In The Loop) で十分議論されてきた話題ではあるが、テ\\nキスト生成 AI利活用のリスクを考える上で特に重要であるので、本文書で取り\\n上げる。  \\n軽減策  \\n分類やラベリングの場合、どのような間違えがどこまで許容できるかを明確\\nにした上で利活用を検討する。  \\n４．２  バッチ処理での利用の期待品質 の箇所も参照していただきたい。  \\n2) テキスト生成 AIの生成物を文章として扱うケース  \\nテキスト生成 AIは分類やラベリングといった従来の AIと違って、自然な文\\n章を生成する点に、その特徴がある。このリスクは (1)どのような文章を (2)誰', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 30}), Document(page_content='29 が(3)どのような目的で利活用するか、に応じて検討が必要なため、この章で\\nはリスクそのものの説明は行わず、その内容は ４ 調達実施前時のテキスト生\\n成AI固有の留意点 で紹介する。ただし、これらリスクの軽減策には共通する\\nところが多い。  \\n軽減策  \\n(1)生成物の出力形式を指定する  \\nテキスト AIの生成物の出力形式を指定することで、以下の 3種類のメリット\\nがある  \\n(1) 出力される文章の内容が期待するものに近づく  \\n(2) 推論の過程を誘導する出力形式を採用することで生成物の品質が良くな\\nる \\n(3) 何らかの理由で出力形式通りでない結果が生成された場合、 テキスト生\\n成AI以外のプログラムで行われる 単一のif文レベルの簡単な処理 によ\\nりエラー判定ができる  \\n(2) 事前に十分テストする  \\nテキスト生成 AIの利活用では十分なテストとは何か、から固有の考え方が必\\n要となるため ５.２ テキスト生成 AIによる生成物の品質評価・品質保証に\\nついてのリスクとその軽減策 で詳細に述べる。  \\n５.２ テキスト生成 AIによる生成物の品質評価・品質保証についてのリス\\nクとその軽減策  \\nテキスト生成 AIの品質に関わるテストが十分に行われないことにより、プロ\\nジェクトの品質目標を満たさないシステムをリリースしてしまうリスクが発生\\nしやすくなる。テストが不十分で あること自体のリスクはテキスト生成 AI固有\\nでなく情報システム全般で共通するが、テキスト生成 AIによる生成物の品質を\\nどのように評価・保証するか、についてはテキスト生成 AI固有と考えられるリ\\nスクがいくつか存在する。本文書では以下の 3つのリスクについて考察を行う。  \\n(1) 生成結果がばらつくことに起因するリスク  \\n(2) 品質評価が困難である リスク  \\n(3) テストケースのカバレッジ が不十分なことに 起因するリスク  \\nこれらのリスクは、テキスト生成 AIの生成物はテスト済みのものだけ用いる\\n方策によって大きく軽減するが、その方策を有用に 用いるためにはいくつか制\\n約がある。その制約について ５．２ ４） テスト済みの生成物のみを用いる\\n場合の工夫 で考察する。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 31}), Document(page_content='30 1) 生成結果がばらつくことに起因するリスク  \\nテキスト生成 AIの機械学習モデルの推論過程には一般にばらつきが生じるこ\\nとがある。そのため同じ入力値であっても、対応する生成物が毎回同じ結果に\\nならず、 ばらつきまで考慮した評価が必要になる 。結果の制御困難なばらつき\\nはテキスト生成 AIではない一部の AIシステムでも起こりうるが、大半のテキ\\nスト生成 AIで生成物のばらつきが見られることとその影響の大きさから、本文\\n書で取り上げる。  \\n想定リスク  \\n事前にテストした結果と異なる結果を返すリスクが生じやすい。具体的にど\\nのようなリスクが発生するかはユースケースに依存する。ここでは、ユースケ\\nースにあまり依存しない一般的な軽減策を述べる。  \\n軽減策  \\n(1) ばらつきに関するパラメータを調整する  \\nばらつきに関するパラメータを調整し、ばらつきを抑制する。この方法では、\\n同じ入力に 対して毎回同じ結果になる確率は上がるが、利用するサービスや機\\n械学習モデルによっては、常に同じ結果になることは保証されないことも多く、\\n注意が必要である。  \\n(2) 生成物の出力形式を指定する  \\n生成物の出力形式を指定することで、ばらつきを軽減することができる。\\n5.1.2 テキスト生成 AIの生成物を文章として扱うケースの (1) と同じ手法なの\\nでそちらを参照いただきたい。  \\n(3) 同じテストを繰り返し行う  \\n品質評価時に同じ入力値で何回かテストし、生成物のばらつきが許容できる\\n範囲か、ばらついた場合でも常にテストをパスできるかの検討を行 う。 \\nこれは、生成物にばらつきが存在することを前提とした上で、テストの方法\\nでそのリスクを軽減する方法である。  \\n実際に何回テストするか等の詳細はユースケースによって異なる品質要件や、\\nどのような入力に対してどのような出力を求めるかによって異なる。テキスト\\n生成では生成結果に長文や創造性が求められるケースでばらつきが生じやすい。  \\n(4) 同じ入力に対し同じ出力を返す仕組みを、テキスト生成 AIモデルの外側で実装する  \\nどうしても毎回同一の結果でなければならない時は、推論時に入力と生成物', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 32}), Document(page_content='31 のペアを保存しておき、過去に同じ入力であった場合にはテキスト生成 AIを利\\n用せずに当時の生成物を返す等といった外側のアプリケーション側の工夫で対\\n策を実施す る。テキスト生成 AIサービスの中にはその種の機能が備わっている\\nものもあるため、自前で実装する前に、その機能や仕様について確認すること\\nを推奨する。  \\n2) 生成物の品質評価が困難であることに起因するリスク  \\nア 全般的な想定リスク  \\nテキスト生成 AIの成果物は、数値やラベルの予測等の精度等の定量的な指標\\nによって評価可能なケースと異なり、テストケースに対してその生成物が妥当\\nかどうかの評価は人間による定性評価の依存度が高くなる。そもそも品質をど\\nの観点で評価すべきか 、は個々のユースケースに依存するため、 ４ 調達実施\\n前時のテキスト生成 AI固有の留意点 で考察する。ここでは定性評価の実施全\\n般のリスクである、評価者の主観に基づくバイアスの混入、費用や開発リード\\nタイムの増加を軽減する方法を提案する。  \\n軽減策  \\n(1) 知識の有無を選択問題によって評価する  \\n正しい知識が反映されているか のみを確認する場合は、選択問題を用意しテ\\nキスト生成 AIを使ったシステムに回答させるといった方法をとることで、基準\\nを明確にできる。この水準まで明確化すると定量的な評価が可能になり、評価\\nの自動化ができる。  \\nイ 評価者の主観に基づくバイアスに起因するリスク  \\nテキスト生成 AIの成果物を人間による定性評価を行う場合、その評価者の主\\n観 、つまり知識や経験や文化的背景の違いなど多様な要因により、なんらか\\nのバイアスが発生する。その結果、期待された品質を達成していないことが実\\n用化してから発覚するリスクが起こりうる。ここではそのリス クを軽減する方\\n策を提案する。  \\n軽減策  \\n(1) 評価観点や基準を明確にする  \\nテキスト生成 AIの生成物の良し悪しをただ漠然と評価させるのではなく、問\\n題や課題点を分解して、評価観点や基準を明確にすることで、主観に基づくバ', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 33}), Document(page_content='32 イアスを抑止できる。例えば、検索拡張生成  (RAG, Retrieval Augmented \\nGenerative ) の技法、つまり文章検索で関連文章を抽出し、それを大規模言語モ\\nデルにプロンプトとして渡す手法を用いる場合は  \\n(1) 質問文に対して適切な関連文章が抽出できているか  \\n(ア) もし想定していた関連文章があれば、 それをちゃんと抽出して\\nいるか（再現率の観点）  \\n(イ) 抽出した関連文章に不適切なものが含まれていないか（適合性\\nの観点）  \\n(2) 関連文章に対して大規模言語モデルの出力が適切か  \\n(ア) 出力結果に含まれている固有名詞は関連文章内に含まれている\\nか \\n(イ) 出力結果の内容は関連文章内で言及されているものか  \\n(ウ) 複数の関連文章の結果を統合している場合、その論理の繋がり\\nは自然か  \\n(3) 最終的な生成物は求められる品質をクリアしているか  \\n(ア) 十分読みやすいか（ユースケースに応じてもっと観点を明確に\\nする） \\n(イ) 出力形式は意図通りになっているか  \\n等の観点や評価項目が考えられる。分解したところで、主観に基づくバイア\\nスの影響は完全に除外できないが、分解しない場合と比べて大幅に抑制可能で\\nある。  \\n(2) 複数人により独立に実施する  \\n1つの項目に定性テストを行う人間を複数人アサインし、それぞれが独立に\\n評価した内容を総合することで主観に基づくバイアスを抑止できる。いわゆる\\nダブルチェック、トリプルチェックである。  \\nただし、その複数人が同じ種類のバイアスをもっている時はリスクが軽減せ\\nず、人件費や開発リードタイムは明確に増加するといった欠点 も多い。  \\nウ 費用や開発リードタイムの増加に起因するリスク  \\n定性テストを実施するにあたって、人員をアサインした場合にその人件費が\\n増加し、また定性テスト自体も時間のかかる工程であるため開発リードタイム\\nの増加を招きやすい。これはプロジェクト管理の観点から明確なリスクである。  \\n軽減策  \\n(1) 機械的な品質評価手法を導入する', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 34}), Document(page_content='33 人手によらず機械的な品質評価を行うことで、費用や開発リードタイムを抑\\n制することができる。テキスト生成の文脈では、機械的評価手法を大別すると\\n以下の2種類がある。  \\n(1) n-gram等の深層学習の発展以前から用い られてきた技術をベースとする\\nもの \\n(2) Transformer 等の深層学習をベースとするもの  \\nこの両方とも正解のテキストデータ、つまり入力に対して尤もらしい文章を\\n事前に用意しておく必要がある。  \\nまだまだ発展途上の分野であることから詳細は付録の ８ 文章間の類似性の\\n機械的評価方法について  で述べる。  \\n(2) 人間の評価者が行うテストケースを絞り込む  \\n単純に品質評価の対象のテストケースを絞り込めば、その分だけ品質評価に\\n関する費用や開発リードタイムを削減することができる。当然ながらその分だ\\nけテストが行われないことになり、プロジェクトの品質要件を満たさないシス\\nテムがリリースされる危険性は高くなる。そもそもテストケース自体のカバレ\\nッジを十分に上げることが困難であり、その解説を ５．２  ３） テストケー\\nスのカバレッジ が不十分なことに 起因するリスク  の節で行う  \\n人間の評価者が行うテストを、機械的品質評価の結果を用いて特定の基準で\\n絞り込むことで、一部だけを実施するといった、機械的品質評価と組み合わせ\\nた絞り込み方法を用いる手法も考えられる。この方法により、テスト対象のテ\\nストケースを減らすことなく、人間の評価者が行うケースを合理的に減らすこ\\nとができる。特に、評価者に高度な専門知識を求めるケースでは有益な方法で\\nある。  \\n3) テストケースのカバレッジが不十分なことに起因するリスク  \\nテストケースごとの品質評価が仮に完璧に実施できたとしても、テストケー\\nス自体が十分でないことに起因し 、プロジェクトの品質要件を満たさないシス\\nテムがリリースされるリスクが存在する。このリスク自体は情報システムの開\\n発において一般的なものであるものの、テキスト生成 AIでは入力が自然文に近\\nいケースが大半であると考えられ、テストケースのカバレッジを十分確保する\\nことが困難であり、その軽減策も独特であるため本文書に含めた。  \\n想定リスク  \\nテキスト生成 AIの入力、特にプロンプトには自然な文章が入力され、文中の\\nごく一部が違っただけで生成物が大きく変化する可能性がある。この特性から', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 35}), Document(page_content='34 正常系のユースケースの入力を洗い出すことが不可 能に近く、理想的なテスト\\nケースと比べてかなり狭い範囲でしかテストできない。  \\nテキスト生成 AI以外のシステムでは、キーワード検索システムがこれに類す\\nる。しかし、以下の 2つの条件の違いにより、テキスト生成 AIを用いたシステ\\nムの方がテストケースのカバレッジの確保がより困難になっている。  \\n(1) 検索システムで想定される入力  (クエリ) のキーワードの集合よりも文\\n章の多様性が高い  \\n(2) クエリやアイテムのベクトル表現化を行わない古典的なキーワード検索\\nシステムではクエリにキーワードを一つ追加した時のシステムの挙動が\\n予測できたが、テ キスト生成 AIでは挙動の予測が不可能に近い  \\n軽減策  \\n(1) 過去に実際にあったやりとりをそのままテストケースに含める  \\nすでに存在するシステムや業務フローの一部をテキスト生成 AIに置き換える\\n場合、過去に実際にあったやりとりをそのままテストケースにすることができ\\nる。例えばヘルプデスク業務の一部をテキスト生成 AIで置き換える場合は、過\\n去に実際にあった問い合わせ内容とそれに対する回答を、プロンプトと正解デ\\nータとしてテストケースに利用できる。  \\nこの手法では安価に大量にテストケースを入手できる。しかし、過去のやり\\nとりをテストケ ース化しやすい形式で保存していない場合や、全く新規のシス\\nテムや業務フローを構築する際にはこの手法が使えない。  \\n(2) 作成したテストケースの入力文の言い換え処理をテキスト系生成 AIに実施させる  \\nテキスト生成 AIではプロンプトが１文字異なっただけで出力する結果が大き\\nく変わる可能性がある。この性質から、とあるプロンプトでそこからの生成物\\nの品質評価を実施したとしても、同様の意味合いをもつプロンプトでの生成物\\nの品質は保証できない。そこで、テキスト生成 AIを用いてテストケースの入力\\n文を言い換えさせることでテストケースを増加さ せる手法を採用することがあ\\nる。この手法を用いることで言い回しが異なったケースを評価できるようにな\\nる。 \\nこの手法のデメリットは、テキスト生成 AI実行に関するコストが増えること\\nである。また、評価時のエラーの原因に「テキスト系生成 AIの言い換えミス」\\nが含まれるようになり、言い換え処理自体の品質が一定以上でないとテストに\\n関するコストがかえって増大する可能性もある。  \\n(3) 事前にテストしたケースのみでテキスト生成 AIの生成物を利用する', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 36}), Document(page_content='35 テキスト生成 AIの生成物の品質を事前にテストできていない範囲がある場合\\nは、その範囲において生成物を用いないこと によりリスクを回避できる 。この\\n方法を採用すると、テキスト生成 AIの利用はすべてバッチ処理で行い、オンラ\\nインではテキスト生成ＡＩを使わないことになる。オンラインでテキスト生成\\nAIを使わない、といった選択をとることで、 インフラコストやレスポンスタイ\\nムの改善 等の副次的な効果 も見込める 。 \\nこの手法のデメリットは、テストケースが十分な量になるまで、実証時にテ\\nキスト生成 AIによる恩恵がほとんど受けられない ことである。  \\n4) テスト済みの生成物のみを用いる場合の工夫  \\n今までの議論の繰り返しになるが、 テキスト生成 AIの品質保証を実現する最\\nも安全な手法は、テストしていないケースを用いないこと（ 5.2.3-(3) 事前\\nにテストしたケースのみテキスト生成 AIの生成物を利用する）である。 ここで\\nは、今までの議論の関係性を明確にするためのまとめを行う。  \\nこの手法を最大限利用するために大量のケースでテストすることが重要であ\\nる。その手法には以下のものがある。  \\n(1) テスト対象のケースを増やす  \\n(ア) ５．２  ３）(1)過去に実際にあったやりとりをそのままテ\\nストケースに含める  \\n(イ) ５．２  ３）(2)作成したテストケースの入力文の言い換え\\n処理をテキスト系生成 AIに実施させる  \\n(2) 大量のテストケースを評価する  \\n(ア) ５．２  ２）ウ  (1)機械的な品質評価手法を導入する  \\nテストケースを増やすだけではなく、テストケースあたりの評価の品質\\n向上も重要である。その手法には以下のものがある。  \\n(3) 生成物のばらつきに対処する  \\n(ア)   ５．２  １）ア (1)ばらつきに関するパラメータを調整する  \\n(イ)   ５．２．１ ）(3)同じテストを繰り返し行う  \\n(4) 評価方法を工夫する  \\n(ア) ５．２  ２）ア  (1)知識の有無を選択問題によって評価する  \\n(イ) ５．２  ２）イ (1)評価観点や基準を明確にする   \\n(5) 評価者のアサインを工夫する  \\n(ア) ５．２  ２）イ  (2)複数人により独立に実施する  \\n(イ) ５．２  ２）ウ  (2)人間の評価者が行うテストケースを絞り\\n込む \\nその他にも、 ３．１  ２）Ｃ）過去のテキスト生成 AIの生成物を再利用す', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 37}), Document(page_content='36 る の手法を使うことで、サービス利用者からの入力文章がそのままの形で テ\\nストケース に含まれていなくても、 類似した想定入力文章に対応するテスト済\\nみのテキスト生成 AIの結果を返す、といった工夫を行うことで、現実的な数の\\nテストケースでも実用的なシステムを構築しやすくなる。  \\nこの入力文章とテストケースの判定手法は 他にも、５．２  ２）ウ  (1)機\\n械的な品質評価手法を導入する  で述べた方法や、入力文章に形態素解析、\\n品詞フィルタリング、固有表現抽出を行い、その結果に基づくキーワード検索\\n結果に基づいた回答結果をテストケースに適用する等の手法が考えられる。こ\\nの手法を用いた場合、 ５．２  ３）(2)作成したテストケースの入力文の言い\\n換え処理をテキスト系生成 AIに実施させる  の必要性は大きく下がる。  \\nこの考え方は、テキスト生成 AI以前のチャットボットでの応答シナリオの充\\n実にのみテキスト生成 AIを使う、といった考え方と同じである。チャットボッ\\nト以外でのユースケースでも、テキスト生成 AIの利活用のスコープを適切に限\\n定することは、品質の安定だけでなく、開発時や運用保守時のコストカットや、\\nレスポンスタイム向上によるユーザビリティの改善にもつながるため、まずは\\n「本当に テキスト生成 AIが必須の処理なのか」 「他の自然言語処理技術で代用\\nできないか」の検討を行うことを推奨する。この検討の具体例 は３．１  ２）\\n(2) テキスト生成 AI以外の手法を採用する  で簡単に紹介した。  \\n５.３ 5章 まとめ \\n \\n設計・開発時には、テキスト生成 AI固有のリスクを特に注視する必要がある。\\n本章では、生成物の品質向上とその評価に重点を置いたリスク軽減策を提案し\\nた。特に、テキスト生成 AIをバッチ処理でのみ用い、テスト済みの結果しか返\\nさない形でのチャットによる情報検索のあり方の提案について述べた。適切な\\n品質保証プロセスの確立が、信頼性の高いシステム構築に不可欠であり、継続\\n的な品質管理が重要な役割を担う。本章がその確立の一助となれば幸いである。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 38}), Document(page_content='37 ６ サービス実施時に留意すべきテキスト生成 AI固有の留意点  \\n \\n本章の目的は、サービ ス実施時におけるテキスト生成 AIの利活用に伴う固有\\nのリスクを管理し、業務の実績データや非機能要件の達成度を評価する手法を\\n提供することである。スコープは、サービスが稼働し始めた後の実際の運用環\\n境でのモニタリングと、継続的な改善サイクルの方法論に焦点を当てている。\\nこれはテキスト生成 AIをどのように利活用するかによって観点が異なるため、\\nユースケースごとに述べる。  \\n６.１ 業務の実績データや利用者要望を分析できているか  \\n1) チャットでの利用の場合  \\nここではユースケースのうち、 チャットインターフェースで利用者サービス\\n利用者とインタラクティブに対話する機能としてテキスト生成 AIをオンライン\\n処理で用いるケース について述べる。 一般的なシステム開発と同様に、予算要\\n求時に設定した KPIを測定する。このユースケースで特に留意すべき点は、 サ\\nービス利用者 からのチャット入力文の実績データの取り扱いである。チャット\\nインターフェースでテキスト生成 AIとインタラクティブにチャットをすると、\\nサービス利用者 の体験としてはヒト相手にメッセージを送るものに近くなる傾\\n向にある。そのため、利用規約やプライバシーポリ シーで明記してあったとし\\nても、テキスト生成 AIへの入力文をシステム管理者が実績データとして確認す\\nること自体をプライバシーの侵害とみなされるリスクがある。このリスクの軽\\n減策として、実績データの取り扱いをプライバシーに配慮した形で定めそれを\\n厳密に運用するのは大前提とし、 サービス利用者 の感情面を配慮したサービス\\nデザインを熟慮することが挙げられる。  \\n2) バッチ処理での利用の場合  \\nここではユースケースのうち、 大量の文章に対してラベル付けやテキストデ\\nータ変換、その他翻訳や要約や文章作成等の自然言語処理を行う機能としてテ\\nキスト生成 AIをバッチ処理で用いるケース について述べる。 一般的なシステム\\n開発と同様に、予算要求時に設定した KPIを測定する。 非機能要件 として、最\\n大同時リクエスト数やリクエスト成功率、目標処理時間等のシステム指標が求\\nめられているはずなので、それらを適切な基準で監視する。  \\n3) 情報検索での利用の場合  \\nここではユースケースのうち、 情報検索を目的としたサービスで検索エンジ', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 39}), Document(page_content='38 ンの補助としてテキスト生成 AIをオンライン処理で用いるケース につい述べる。\\n一般的なシステム開発と同様に、予算要求時に設定した KPIを測定する。機能\\n要件として、最大同時リクエスト数やリクエスト成功率、レスポンスタイムの\\nサービスレベル等のシステム指標が求められているはずなので、それらを適切\\nな基準で監視する。それ以外にもテキスト生成 AIを導入したことによる検索結\\n果の品質改善への介入効果を適切に行うため、可能であれば A/Bテストを積極\\n的に行う。 A/Bテストでは、例えばテキスト生成 AIを導入した場合としなかっ\\nた場合の２群を用意し、それぞれに対してランダムにサービス利 用者を割り当\\nて、２群間でのクリック率や直帰率等の行動指標に発生した差を統計的に確認\\nする。テキスト生成 AIを導入することにより運用コストが増大するので、その\\n費用対効果が妥当なものであるかはしっかりと分析すべきである。  \\n4) 自然言語からのプログラム作成利用の場合  \\nここではユースケースのうち、 ダッシュボードやソースコード等をサービス\\n利用者の自然言語により記述可能にする機能としてテキスト生成 AIをオンライ\\nン処理で用いるケース について述べる。 一般的なシステム開発と同様に、予算\\n要求時に設定した KPIを測定する。特に注目す べき指標は (1)サービス利用者 の\\n自然言語から適切なアウトプットが出力された割合 (2)テキスト生成 AIにより\\n業務時間がどこまで短縮できたか、である。  \\n(1)サービス利用者 の自然言語から適切なアウトプットが出力された割合に\\n関しては、不適切な結果であった場合にフィードバックされる機構が欲しくな\\nるが、SaaS製品を導入している場合難しい場合も多い。そこで、アンケート調\\n査や内部向けの報告窓口の設置によって間接的に推定する方法を検討する。  \\n(2)テキスト生成 AIにより業務時間がどこまで短縮できたかの測定は、実際\\nに職員に テキスト生成 AIの有無の条件ごとに作業させて測定する手法が比較的\\n正確だが、実験実施の負担が大きい。そのため現実的にはヒアリングやアンケ\\nート調査に頼らざるを得ない場合が多い。そもそもダッシュボードの操作やソ\\nースコード作成が元々できない職員の場合の、業務短縮効果は、そのスキルの\\n平均取得時間を含められる。ただし、このスキル取得に係わる時間を業務短縮\\n効果に含められるのは、その職員の最初の 1回の作業だけであり、重複カウン\\nトしないようにする。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 40}), Document(page_content='39 ６.２ 非機能要件に関する実績データを把握しているか  \\n1) チャット利用の場合  \\nここではユースケースのうち、 チャットインターフェースで利用者サービス\\n利用者とインタラクティブに対話する機能としてテキスト生成 AIをオンライン\\n処理で用いるケース について述べる。  \\nサービス利用者からの実際の入力がログの形で入手可能になり、それらがテ\\nストケースに含まれていなかった場合、テストケースに追加することができる。\\nこれは４．１  チャットでの利用 の期待品質  でも述べた。この実際の入力を\\nベースとしたテストケースを用い、改めて品質評価を行うことで 非機能要件に\\n関する実績データが得られる。 ただし、 ６．１  業務の実績データや利用者\\n要望を分析できているか  で述べたように、重要な実績データである サービス\\n利用者からの入力文の扱いはプライバシー侵害だとみなされないように注意す\\nる。 \\n2) バッチ処理での利用の場合  \\nここではユースケースのうち、 大量の文章に対してラベル付けやテキストデ\\nータ変換、その他翻訳や要約や文章作成等の自然言語処理を行う機能としてテ\\nキスト生成 AIをバッチ処理で用いるケース について述べる。 ４．２  バッチ\\n処理での利用 の期待品質  で述べたテストケースを実績データから増やし、そ\\nれをテストすることで、非機能要件に関する実績データが得られる。  \\n3) 情報検索での利用の場合  \\nここではユースケースのうち、 情報検索を目的としたサービスで検索エンジ\\nンの補助としてテキスト生成 AIをオンライン処理で用いるケース につい述べる。\\n４．３  情報検索での利用 の期待品質  で述べたテストケースを実績データか\\nら増やし、それをテストすることで、非機能要件に関する実績データが得られ\\nる。 \\n4) 自然言語からのプログラム作成での利用の場合  \\nここではユースケースのうち、 ダッシュボードやソースコード等をサービス\\n利用者の自然言語により記述可能にする機能としてテキスト生成 AIをオンライ\\nン処理で用いるケース について述べる。 ４．４  自然言語からのプログラム\\n作成での利用 の期待品質  で述べたテストケースを実績データから増やし、そ\\nれをテストすることで、非機能要件に関する実績データが得られる。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 41}), Document(page_content='40 ６.３ 業務で扱うデータの品質を維持しつつ適切なライフサイクル管理を\\n行っているか  \\n \\n一般的なシステム開発のデータ品質とライフサイクル管理はデータの不整合\\nの発生抑止に重視が置かれるが、ここでは AIプロジェクトの観点でのデータの\\nライフサイクルについて述べる。これは、 (1)実際の利用 実績が当初想定から\\n乖離あるいは変化、 (2)利用した機械学習モデル (ここでは大規模言語モデル )\\nの変化、の 2つの変化により機能要件・非機能要件を満たさなくなるリスクの\\nことを指す。機能要件が満たされているかの監視は一般的なシステム開発でも\\n共通した話であり、非機能要件が満たされているかの監視については ６．２  \\n非機能要件に関する実績データを把握しているか  で述べたので割愛する。  \\n機能要件・非機能要件が満たされなくなる前に気が付く、満たされなくなっ\\nた後に原因分析を行い適切な対策をとる、の両方のために、原因となる変化を\\n観測することは非常に重要である。仮にシステムが機能要件・非機能要件を満\\nたさなくなった場合、その要件を再び満たすための改修だけでなく、サービス\\nの停止や終了も視野にいれた検討も視野に入れるべきである。  \\n(1)実際の利用実績が当初想定から乖離あるいは変化したか、についての観\\n測は６．１  業務の実績データや利用者要望を分析できているか  で述べた。\\n特にサービス実施直後は、設計・開発時との想定との乖離がないかをしっかり\\nと確認することを推奨する。  \\n(2)利用した機械学習モデル (ここでは大規模言語モデル )の変化については、\\nテキスト生成 AIの機械学習モデルが直接提供されるケース以外の利用形態につ\\nいては注意すべき点であり、付録の ７．１ ４）アップデート対応に関する\\nリスクと７．２．４） アップデート対応に関するリスク を参照していただき\\nたい。  \\n６.４ ６章 まとめ \\nサービス実施時には、実際の運用データをもとにした継続的な品質評価が必\\n要である。本章では、業務実績データの分析と非機能要件の達成度の検証に焦\\n点を当て、適切なライフサイクル管理を通じて、サービスの持続可能性を保証\\nするための留意点を強調した。これらの実施により、テキスト生成 AIの持続的\\nな価値提供が実現できる。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 42}), Document(page_content='41  まとめ \\n \\n本文書ではテキスト生成 AIの各種提供形態とユースケースに基づいたリスク\\nを検討し、それに対する軽減策やその留意点を述べた。一方で、これらがより\\n実践的な内容になるためには、実行可能なフレームワークやチェックリストの\\n形式をとる方が望ましいが、本文書はその水準にまだ達していない。あくまで\\n留意点を述べているだけである。特に下記の箇所では実践的なフレームワーク\\nやチェックリストの整備が重要であると考えている。  \\n➢ テキスト生成 AIの提供形態の選択プロセス  \\n➢ 利用シナリオ、セキュリティ要件、費用対効果等を考慮した提供形\\n態決定の基 準 \\n➢ コスト削減戦略の具体化  \\n➢ 各提供形態におけるコスト削減の具体的な方法と手順を含んだ、コ\\nスト削済のためのアクションプラン等  \\n➢ リスク管理計画  \\n➢ リスクの特定、評価、対応策の立案を含む詳細なプロセスやチェッ\\nクリスト等  \\n➢ 非機能要件のテストと評価  \\n➢ 非機能要件に関する評価基準やテスト方法等  \\n➢ 品質保証プロセス  \\n➢ 品質を評価し、維持するための具体的な手法やツール等  \\n➢ サービス利用者フィードバックの収集と分析  \\n➢ フィードバックの体系的な収集と分析、そしてそれをシステム改善\\nにまとめつけるためのプロセス等  \\n➢ 運用実施時の品質管理  \\n➢ 責任体制を明確にするための、運用実施時における品質管理のプロ\\nセス等 \\n現段階（ 2024年5月現在）では、フレームワークやチェックリストを作成で\\nきる水準での知見の蓄積が不足している。今後、検証を勧めていく中で知見が\\n更新され、実用的なフレームワークやチェックリストを追記する改定を目指し\\nている。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 43}), Document(page_content='42 付録 \\n特に、技術的に込み入った内容かつ変化が早い領域について付録の形で紹介\\nする。  \\n７ 提供形態ごとの想定リスク  \\n \\n本章の目的は提供形態による違いに伴うリスクの想定とその軽減策を示すこ\\nとである。スコープは、ライセンス、調達容易性、機密性、アップデート対応、\\nベンダーロックイン、コストマネジメントの 6つの観点に焦点をあて、想定リ\\nスクと軽減策を整理する。  \\n７.１ テキスト生成 AIを組み込んだサービスとして提供されるケースに関\\nするリスクとその軽減策  \\n \\nテキスト生成 AIが何らかのサービスに組み込まれた状態で提供される利用形\\n態を想定する。 ChatGPT やGithub Copilot のような SaaS型のサービス以外に\\nも、Bing Chat やGoogle Bard といった広告課金型のサービスも該当する。テ\\nキスト生成 AIは有用な用途が広く、今後さまざまなサービスに組み込まれてい\\nくと考えられる。  \\n2024年4月現在、各府省庁で生成 AIを利用したサービスで要機密情報を扱\\nう条件に  (1) 必要なセキュリティ要件が守られる契約を実施（一般的に約款\\n型では厳しい） (2)クラウドサービス（参考 : 政府機関等の対策基準策定のた\\nめのガイド ライン（令和５年度版） の4.2 クラウドサービス）に関わる係る関\\n連規程に基づく対応  (政府情報システムのためのセキュリティ評価制度\\n（ISMAP）による認証が一例 )を行ったうえで、 AI戦チームに報告・了承をとる\\n必要がある。 (参考: ChatGPT 等の生成  AI の業務利用に関する申合せ（第２\\n版）) \\n1) ライセンスに関するリスク  \\n生成AI固有の規約として、生成物を競合他社による AI学習利用を禁止して\\nいる例が挙げられる。 (参考: OpenAI社の利用規約 )。 \\n2) 調達容易性に関するリスク  \\n広く市場に流通しているサービスの調達時に特別なリスクは考えにくい。た\\nだし、サービスの背後で大規模言語モデルを Web API 経由で利用していた場合、\\nWeb API 側のアップデートにより以前同じものを調達できなくなるリスクが存', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 44}), Document(page_content='43 在する。詳細は ７．２．４） アップデート対応に関するリスク  を参照いた\\nだきたい。  \\n要機密情報を扱う場合、該当サービスが政府機関等のサイバーセキュリティ\\n対策のための統一基準群等のセキュリティ要件を満たすかには注意が必要であ\\nる。 \\n3) 機密性に関するリスク  \\n機密性の議論は、 個人情報を含めた要機密情報を扱う場合のセキュリティ要\\n件の一つでしかなく、テキスト生成 AI固有のリスクではない。テキスト生成 AI\\nでは、教師デー タとして与えた文章らしい出力を返すような機械学習が行われ\\nるため、ユーザからの入力を AI開発者が教師データとして扱うことによる機密\\n流出が問題視されてきた。しかし、テキスト生成 AIへの入力の機密性が守られ\\nないケースは機械学習であること以外にも多岐にわたり、利用 時に意識するこ\\nともサービス契約者との契約面やシステムがセキュアであるかが主であるため、\\nついての規約や契約の精査と、情報システムとして十分なセキュリティ対策が\\n施されている必要があるかを確認 する必要がある。 政府機関等の対策基準策定\\nのためのガイドライン（令和５年度版） の4.2 クラウドサービスを参考にして\\nいただきたい。  \\n4) アップデート対応に関するリスク  \\nテキスト生成 AIを活用したサービスは、その内部で OpenAI社、Anthropic 社\\nやAlphabet 社等のAIモデルを、 Azure、AWSやGCPといったクラウドサービス\\nプロバイダの PaaSを利用していることが多い。この PaaS上のモデルがアップ\\nデートされた場合に、提供されたサービスに挙動が変わることがある。 (参考: \\nOpenAI社のGPT-3.5とGPT-4の性能変化についてまとめている調査結果 ) \\nこの利用形態では、アップデートに伴う挙動の変化を主体的に軽減すること\\nは難しいため、 挙動の変化がリスクになるような使い方をしない、といった利\\n用方針でカバーする方法を推奨する。 ５．２  テキスト生成 AIによる生成物\\nの品質評価・品質保証についてのリスクとその軽減策  も関連した内容を含\\nむため参考にしていただきたい。  \\n5) ベンダーロックインに関するリスク  \\nテキスト生成 AIを用いたサービス固有の特徴として、ロジックの大部分が特\\n定の大規模言語モデルに依存しているサービスが広く出回っている。特に\\nChatGPT に代表される、チャットインターフェース経由でユーザが大規模言語\\nモデルを利用することを目的にしたサービスが挙げられる。この種のサービス', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 45}), Document(page_content='44 利用時にベンダ ーロックインが発生してしまうと (1)他のより優れた大規模言\\n語モデルが利用できない (2)より安価な類似サービスに乗り換えることができ\\nず不必要なコストが発生する、等のリスクが考えられる。  \\n軽減策  \\nチャットインターフェース経由でユーザが大規模言語モデルを利用すること\\nを目的にしたサービスを利用する際に、ベンダーロックインを防ぐために  \\n(1)利用している大規模言語モデルはバージョン情報を含めて明示化されて\\nいるか  \\n(2)大規模言語モデルに入力されるプロンプトの一部やパラメータが隠蔽さ\\nれていないか  \\nの確認が重要である。これらの情報が開示されていれば、他のサービスでも\\nテキスト生成 AIに対して同じような挙動をさせることができる。  \\nまた、過去のチャット履歴の保存機能や、プロンプトをテンプレートとして\\n登録する機能がある場合等 (参考: ChatGPT ではGPTsが該当する )は、それらの\\nデータをエキスポートする機能等のデータの囲い込みを軽減する機能もあると、\\nよりベンダーロックインを回避しやすい。  \\n大規模言語モデルごとの最適なプロンプトの違い等の議論は、 ７．２  ５）\\nベンダーロックインに関するリスク  も参照いただきたい。  \\n6) コストマネジメントに関するリスク  \\nSaaS型の製品を利用する場合、大半の場合でコストがアカウント数とプラン\\nに比例し、コスト予測は容易である。一方で費用対効果が見合うかの試算が非\\n常に難しい。 SaaS型の製品を利用し、行政職員の業務改善効果を期待する場合、\\nその効果測定が重要となる。これはテキスト生成 AI固有の話題ではなく DXや\\nBPRといった分野一般の話題である ため本書では割愛する。  \\n７.２ テキスト生成 AIを利用するための Web APIがクラウドサービスとし\\nて提供されるケースに関するリスクとその軽減策  \\n \\nここでは、クラウドサービスとしてテキスト生成 AIの大規模言語モデルが提\\n供される利用形態を想定している。具体的には、 OpenAI社のGPTシリーズ、\\nMicrosoft 社のAzure OpenAI Service 、Amazon社のAWS Bedrock やAlphabet 社\\nのGCP Vertex AI 等を想定している。これらのサービスでは Web API として大\\n規模言語モデル を主に従量課金、一部で定額課金、で利用することができるだ\\nけでなく、 Web API を便利に使うための Web アプリケーションもセットで提供', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 46}), Document(page_content='45 されることが多い。  \\n1) ライセンスに関するリスク  \\nテキスト生成 AI固有でなく、サービス利用時の契約に関する一般的なリスク\\nであるため割愛する。生成 AI固有の規約としては、生成物の競合他社による AI\\n学習への利用を禁止している点が挙げられる。 (参考: OpenAI社の利用規 約) \\n2) 調達容易性に関するリスク  \\n一般的に市場に流通しているサービスを念頭においており、調達は容易のた\\nめリスクは見当たらない。ただし、生成 AIに関連するクラウドサービスの最先\\n端の機能ではアクセスが制限されていたり、利用可能なリージョンが限定され\\nていたりと制約が多く、その制約のために調達が容易でない場合もありうる。\\nまた、大量の計算リソースを必要とする場合は、クラウドサービスの利用であ\\nってもその計算リソースを確保できない状況もありうる。  \\n3) 機密性に関するリスク  \\nテキスト生成 AI固有でない AIシステムの一般的なリスクのため割愛する。\\n一般的な AIシステムと同じく学習用のデータや推論用のデータがどこにどのよ\\nうに保存されるかとそれに伴う想定リスクについての整理が重要である。  \\n4) アップデート対応に関するリスク  \\n従来のAIシステムと比べて、事前学習済みの大規模言語モデルを追加学習無\\nしでも十分に利用できるケースが多い。その事前学習済みの大規模言語モデル\\nの利用を前提としていると、その日々アップデートや保守終了  (End Of \\nservice L evel、EOL)によって、自分達で十分にテストできていない大規模言語\\nモデルを利用せざるを得ないケースが起こりうる。特に事業者や国民向けの政\\n府情報システムではリスクが大きいと予想される。  \\n軽減策  \\n(1)テスト済みの結果しか返さない  \\nもっともリスクが軽減される方法である。 ５．２  テキスト生成 AIによる\\n生成物の品質評価・品質保証についてのリスクとその軽減策 、特に５．２  \\n４） テスト済みの生成物のみを用いる場合の工夫  を参考にしていただき\\nたい。 \\nリスク影響の評価', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 47}), Document(page_content='46 大規模言語モデルが EOLを迎える前に、移行候補の大規模言語モデルで十分\\nな性能かどうかを検証できていれば、アップデートに関するリスクの影響を事\\n前に評価できる。リスク影響が十分に低ければ特に軽減策を取る必要がなくな\\nる。一般的な傾向として大規模言語モデルはより良い性能になるよう改良され\\nていくものなので、軽減策にコストをかける前にリスク影響を 見積もることを\\n推奨する。  \\n(1)新しい大規模言語モデルを開発内部でテストする  \\n新しい大規模言語モデルに実際のプロンプト等の入力を入れて、その生成物\\nの品質が許容できるものかを評価する。 ５．１  テキスト生成 AIの生成物の\\n品質面への懸念  を参考にしていただきたい。  \\n(2)ユーザビリティの悪化を検知する  \\n開発者による内部テストではなかなか評価しにくい総合的なユーザビリティ\\nの評価は、実際に新しい大規模言語モデルを段階的にリリースすることによる\\nA/Bテストが有効である。 A/Bテストとは、 サービス利用者 をランダムに違う条\\n件に割り振り、その条件毎で利活用のされ方を定量的に比較する手法である。\\nA/Bテスト自体はテキスト生成 AI固有の評価方法ではないので詳細は割愛する。  \\n5) ベンダーロックインに関するリスク  \\n他のクラウドサービスプロバイダの Web API に切り替える場合、以下の 3点\\nの対応が必要となる。  \\n(1) 異なる大規模言語モデルを利用する場合、プロンプトのチューニング  \\n(2) Web APIに送るリクエストボディのフォーマット  \\n(3) その他、エンドポイントやネットワークの設定、認証情報等  \\nこの切り替え対応の実施コストが極めて高い場合、ベンダーロックインに関\\nするリスクが増大する。  \\n(1)は大規模言語モデルによってプロンプトの効率的な書き方が異なる点に\\n注意が必要である。 (参考: Anthtropic 社のClaudeでは \\\\n\\\\nHuman: に特別に\\n意味をもたせている ) \\n(2)はテキスト生成 AI固有の内容でないた め割愛する。パラメータ名やとり\\nうる値が異なる等の違いはあってもクラウドサービスプロバイダ間で似ている\\n傾向がある。  \\n(3)はテキスト生成 AI固有の内容でないため割愛する。  \\n \\n実装レベルでクラウドサービスプロバイダの Web API の違いを意識しないで', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 48}), Document(page_content='47 済む方法の一つに LangChain 等の開発フレームワークの導入も考えられる。し\\nかしフレームワークを導入してしまうと、今度はそのフレームワークにロック\\nインされるリスクが生じる。まだ発展途上かつ発展が早い分野であるため、情\\n報システムの開発体制やエンジニアのスキル等も考慮 しつつ、フレームワーク\\nの安易な導入 といった 早すぎる最適化 をしないよう慎重に検討することを推奨\\nする。  \\n軽減策  \\nテキスト生成 AI固有でない部分、例えばソフトウェア設計時にテキスト生成\\nAIサービスを利用するコンポーネントを適切に分離し、そこだけ変更した場合\\nの評価実験を行いやすくする等のマイクロサービス一般の工夫については割愛\\nする。  \\nテキスト生成 AI固有の部分に関しては、基本的に十分にテストができれば問\\n題ないため、 ７．１  ４） アップデート対応に関するリスク  と同じ内容で\\nある。新しいクラウドサービスプロバイダのテキスト生成 AIサービスを利用す\\nる場合のリスク全般は本章の他の節で記載されている。  \\n7.2.6 コストマネジメントに関するリスク  \\n大規模言語モデルをクラウドサービスプロバイダの Web APIで利用する場合、\\nその料金形態が独特である点に注意が必要である。これは大規模言語モデルの\\n推論時に、入力のプロンプトや出力される生成物の文書量のサイズが増えると\\nともに、必要とされる計算リソースが増える傾向がある性質に由来していると\\n考えられる。 入力のプロンプトよりも 生成物の文書 の方がサイズによる計算リ\\nソースの増加影響が 大きい。そのため、多くの場合、入力分のサイズ（一般的\\nにはトークン数、一部文字列長のケースもある）と出力文のサイズのそれぞれ\\nに比例した課金形態となっている。この料金形態によりリクエスト数だけでな\\nく、リクエストの中身やその結果の出力にも大きく費用が依存する形になり、\\nコスト予測が難しくなっている。そのため見積もりミスによる予算超過や利用\\n停止のリスクが起こりうる。  \\n軽減策  \\n(1) 見積もりの精度を上げる  \\n事前テストの結果等から入出力のテキストトークン数や文字数の悲観予測を\\nしておく。トークン数の計算方法は各クラウドプロバイダーから提供されてい\\nる場合も多く事前に確認しておく。  \\n(2) 事前にテスト済みのものしか返さない', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 49}), Document(page_content='48 テキスト生成 AIによる出力結果は事前にテストしたものしか返さない方式を\\n採用することでテキスト生成 AI固有のコストマネジメント上のリスクを大幅に\\n軽減することができる。 ５．２  テキスト生成 AIによる生成物の品質評価・\\n品質保証についてのリスクとその軽減策 、特に５．２  ４） テスト済みの\\n生成物のみを用いる場合の工夫  も参考にしていただきたい。  \\n(3)予算超過を防ぐ  \\nテキスト生成 AIのWeb API方式の提供では、出力トークン数 (文字数)の上限\\nをパラメータで設定できることもできる。このパラメータと入力文字数の制限\\nを設けるプログラムを手前に挟むことで 1リクエストあたりのコスト上限をコ\\nントロールできる。  \\nリクエスト量の制限や、コストアラートの設定等の方法はテキスト生成 AI固\\n有でないクラウドサービス利用一般の話題のため割愛する。可用性をどこまで\\n犠牲にできるかのトレードオフの関係になる点に注ただきたい。  \\nクラウドサービスプロバイダによっては、テキスト生成 AIを従量課金ではな\\nく定額で利用するプランを用意している場合もある。一般にこの契約は高価な\\nため、テキスト生成 AIを大量に利用するケースで選択肢に上がる。  \\n７.３ テキスト生成 AIの機械学習モデルが直接提供されるケースに関する\\nリスクとその軽減策  \\nテキスト生成 AIを、特定 のサービスに組み込まれた形ではなく、 Web API の\\n形式でもなく、大規模言語モデルを自身の環境にデプロイすることで利用する\\nケースを考える。  \\nこのケースではインターネットに繋がらないオンプレの環境だけでテキスト\\n生成AI利活用を完結することができるため、非常に機微な情報を利用する際等\\nに選択肢に上がるが、初期構築や保守運用のコストが高く、利用できる大規模\\n言語モデルも限定される、といったデメリットも存在する  \\n1) ライセンスに関するリスク  \\nソフトウェアの利用のさいに、ライセンスを意識する必要があること自体は\\nテキスト生成 AI固有ではない。オープンソースとされる大規模言語モデルは、\\n元となる大規模言語モデル  (Meta社のLlama2等)を追加学習したものである場\\n合があり、その場合は元となる大規模言語モデルのライセンスも継承している\\nことが一般的であるため、注意が必要である。  \\n生成AI固有の規約としては、生成物の競合他社による AI学習への利用を禁\\n止している点が挙げられる。 (参考: OpenAI社の利用規約 )', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 50}), Document(page_content='49 2) 調達容易性に関するリスク  \\n生成AIの世界的な盛り上がりから計算資源の確保、特に GPU、が難しくなっ\\nている。テキスト生成 AIを学習せずに利用するだけでも計算資源をかなり必要\\nとするため、調達のコストが急騰したりそもそも調達不可能であったりするリ\\nスクが存在する。ただし大規模言語モデルの小型化の研究も盛んである ため、\\n近い将来は必要とする計算資源が少ない大規模言語モデルでも品質要件を十分\\n満たせるようになる可能性が高い。  \\n3) 機密性に関するリスク  \\n特になし  \\n4) アップデート対応に関するリスク  \\n特になし  \\n5) ベンダーロックインに関するリスク  \\n利用した大規模言語モデルが、他のクラウドベンダーでの利用を想定してい\\nない場合に強いベンダーロックインがかかるリスクがある。 ７．２  ４） ア\\nップデート対応に関するリスク  のように、その大規模言語モデルでなけれ\\nばいけないのかを正確に評価することが重要になる。  \\n6) コストマネジメントに関するリスク  \\n７．３  ２） 調達容易性に関するリスク  に述べたように非常に高価にな\\nるリスクがある。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 51}), Document(page_content='50 ８ 従来型の情報検索サービスをテキスト生成 AIにより改善する手法  \\n \\nここでは、データベースや全文検索エンジンが既に存在する場合、それをテ\\nキスト生成 AIにより改善する手法の一例の概要をまとめる。まだ発展途上の\\n分野であるため頻繁な改訂を想定している。\\n \\n図5. 情報検索システムでユーザビリティ向上を生成 AIで実現できる箇所\\n(再掲) \\n \\nNo テキスト生成 AI\\n適用箇所  処理名称  処理内容  備考 \\n1 回答候補の登録  回答候補自\\n体と対応させ\\nる質問文の作\\n成 引用させたいドキュ\\nメントを用いて、事前\\nにQAを大量に生成す\\nる。 ５．２  ４） テ\\nスト済みの生成物の\\nみを用いる場合の工\\n夫 も参照いただき\\nたい \\n2 回答候補の登録  ラベリング  サービス利用者が検\\n索時にラベルで絞り込\\nみ検索ができるように\\n回答候補にラベルをふ\\nっておく。このラベル\\nはランキングアルゴリ\\nズムも特徴量に使うこ\\nともできる  ラベル自体の見直\\nし頻度が少ない場\\n合、テキスト生成 AI\\nでなく特化した教師\\n付き学習モデルを開\\n発することも検討す\\nる', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 52}), Document(page_content='51 3 回答候補の登録  可読性の高\\nいテキストに\\n変換 不要なHTMLや改行コ\\nードの変換、検索結果\\n画面に表示させるため\\nの要約テキストの作成\\n等を行う  不要なHTMLや改行\\nコードの変換はテキ\\nスト生成 AIなしでも\\nルールベースでかな\\nり実現できる  \\nテキストの要約は\\nテキスト生成 AI以外\\nの手法もあるが、ど\\nのような要約にした\\nいかのコンテキスト\\nを含めたテキスト生\\n成AI利用の方が良い\\n場合も多い  \\n4 回答候補の登録  非構造デー\\nタのテキスト\\n変換 図表やイラストや写\\n真等の情報もテキスト\\n検索の対象にするため\\nテキストでの説明を入\\nれる マルチモーダルな\\n大規模言語モデルの\\n利用することで実現\\nできる \\nアクセシビリティ\\n向上のための代替テ\\nキスト作成にもつな\\nがる \\n5 回答候補の登録  同意語・表\\n記ゆれ・シノ\\nニム等対策  回答候補のインデッ\\nクスさせる文章（キー\\nワード検索にひっかけ\\nる用のもの）に元の文\\n章の同意語・表記ゆ\\nれ・シノニム等を登録\\nさせる 全文検索エンジン\\nであれば辞書と設定\\nファイルを登録すれ\\nば、回答候補登録時\\nにインデックスに反\\n映され、クエリにも\\n同じ処理が実施され\\nる \\n辞書ベースのアプ\\nローチが望ましく、\\nその辞書の作成にテ\\nキスト生成 AIを用い\\nる', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 53}), Document(page_content='52 6 サービス利用者\\nの入力 固有表現抽\\n出 サービス利用者の入\\n力から固有名詞や重要\\nだと思われる単語を抜\\nき出し、その単語が正\\n確に含まれる回答候補\\nを検索上位に表示させ\\nる テキスト生成 AI利\\n用でなく、形態素解\\n析と辞書による方法\\nを最優先に検討する\\nこと \\n辞書の作成にテキ\\nスト生成 AIを活用す\\nる方法が考えられる  \\n7 サービス利用者\\nの入力 同意語・表\\n記ゆれ・シノ\\nニム等対策  サービス利用者の入\\n力文に対して、同意\\n語・表記ゆれ・シノニ\\nム等の処理を行う  No5と同等 \\n8 サービス利用者\\nの入力 similarity \\nsearch サービス利用者の入\\n力文章の意味を表現し\\nたベクトル表現\\n（embedding ）に変換\\nし、回答候補のベクト\\nル表現との類似度を計\\n算し、一定以上の類似\\n度のものを検索結果に\\n表出させる、または類\\n似度が高い回答候補を\\n検索上位に表示させる  ９ 文章間の類似\\n性の機械的評価方法\\nについて  で関連す\\nる要素技術に簡単に\\n触れる \\nベクトル表現化の\\nための機械学習モデ\\nルは厳密には生成 AI\\nではないが関連技術\\nであるため、ここで\\n紹介した  \\n回答候補の登録時\\nにもベクトル表現に\\nしておく  \\nベクトル表現に利\\n用する機械学習モデ\\nルは基盤モデルをそ\\nのまま利用する以外\\nにもfine tuning し\\nて用いる方法もある  \\n9 サービス利用者\\nの入力 カテゴリ推\\n定 サービス利用者の入\\n力文に対して事前に定カテゴリ情報の利\\n用は多岐にわたる', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 54}), Document(page_content='53 義したカテゴリを推定\\nし、その推定情報を検\\n索の処理に活用する  例えば、特定のラ\\nベルのついた回答候\\n補を優先表示した\\nり、No6,8,10,11,13\\nのような処理をカテ\\nゴリ毎に返えたりが\\n考えられる  \\nカテゴリ推定の手\\n法は、サービス実施\\n時にはテキスト生成\\nAIではなく、従来の\\n自然言語処理手法の\\n採用の検討を推奨す\\nる \\n10 サービス利用者\\nの入力 意図解釈  サービス利用者の入\\n力から意図を読み取\\nり、より適切な検索結\\n果を提供するために入\\n力を修正する  どのような入力が\\n適切かを事前に定義\\nする必要と、その適\\n切な処理への写像の 2\\nつの処理が必要であ\\nる \\nその処理の構成要\\n素の一つにテキスト\\n生成AIの利用が選択\\n肢になる  \\n変換後の入力文を\\nサービス利用者に明\\n示的に選択させるか\\n否かで検索体験が大\\nきく変わり、どちら\\nが望ましいかはサー\\nビスの特性に依る  \\n11 システムの出力  回答結果の\\n要約や解説  検索結果の回答候補\\nから、よりサービス利\\n用者の入力に対して直テキスト生成 AIの\\n知識ではなく、検索', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 55}), Document(page_content='54 接の返答になるような\\n文章を生成する  結果の回答候補から\\n文章を生成させる  \\nサービス利用者が\\n元の文章を確認でき\\nるように引用元の情\\n報の明記が望ましい  \\n江戸川区のホーム\\nページで導入された\\n機能 \\n12 システムの出力  related \\nquery \\nsuggestion  サービス利用者の入\\n力から、より適切な検\\n索結果を提供するため\\nに入力文を提案する  内部処理自体は\\nNo10と同様 \\n表４ 既存の情報検索システムをテキスト生成 AIで改善する一例', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 56}), Document(page_content='55 ９ 文章間の類似性の機械的評価方法について  \\n \\n文章間の類似性を自動的・定量的に測ることができれば、  \\n(1)テキスト生成 AIの生成物の品質評価の際に正解データとの比較  \\n(2)テキスト生成 AIの生成物の再利用時の際に利用すべき生成物の特定  \\nを大量かつ高速に実現することができる。  \\nテキスト生成 AIの生成物の品質評価では、 ５．２  ２）ウ  費用や開発リ\\nードタイムの増加に起因するリスク  で述べたように、大量のテストケース\\nで評価することが重要であるため、機械的な手法を導入しないと、試行錯誤の\\n実施が困難になる。  \\nテキスト生成 AIの生成物の再利用時の際に、過去の質問応答データの質問文\\n章と入力文が十分に類似していると判定出来る場合は、対応する過去の応答デ\\nータを出力する手法が考えられる。この手法によりテキスト生成 AIをオンライ\\nン処理で利用しないで済むことにより、品質の安定 化や運用費用削減、レスポ\\nンスタイムの向上等の利点がある。 ５．２  ４） テスト済みの生成物のみ\\nを用いる場合の工夫  も参照いただきたい。   \\n文章間の類似性を自動的・定量的に測るための機械的評価手法を大別すると\\n以下の2種類がある。  \\n(1)n-gram等の従来から用いられてきた技術をベースとするもの  \\n(2)Transformer 等の最新のニューラルネットワーク をベースとするもの  \\nこの両方とも正解のテキストデータ、つまり入力に対して尤もらしい文章を\\n事前に用意しておく必要がある。  \\nn-gram等の従来から用いられてきた技術をベースとするものは、例えば\\nBilingual Evaluation Understudy (BLEU) やRecall-Oriented Understudy for \\nGisting Evaluation (ROUGE) といった手法がある。これらは計算コストが少な\\nいため評価の実施が比 較的容易ではあるが、意味がほとんど変わらない語順変\\n化や、否定語の有無、意味がほぼ同じ単語の言い換え等を苦手とし、総じて文\\nの意図を理解した形での評価が困難であると言われることが多い。  \\n一方で、 Transformer 等の最新のニューラルネットワーク をベースとしたも\\nのは何らかの形で文の意図を表現できているとみなすことができる挙動をする\\nため、より洗練されたテキスト品質の評価手法であると考えられる。しかし計\\n算コストが比較的高いため、常に Transformer 等のニューラルネットワークを\\nベースとした評価手法を採用するこ とが正解であるとは言い切れない。また、\\n特定の固有名詞の有無を特に強調したい場合等はルールベースの手法と組み合\\nわせることも考えられる。この Transformer 等のニューラルネットワークをベ\\nースとした評価手法も以下の 2種類に大別される。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 57}), Document(page_content='56 (1)テキスト生成 AIの生成物と正解データのテキストをそれぞれベクトル\\n表現化し、文章間の類似性を評価する  \\n(2)テキスト生成 AIの生成物と正解データのテキストをプロンプトに入れ、\\ngpt-4等の性能が良いとされる大規模言語モデルによって評価させる  \\nベクトル表現化には事前学習済みの Bidirectional Encoder Representations \\nfrom Transformers (BERT) 等が使われ、最も単純な比較方法にはベクトル表現\\n間のコサイン類似度が使われる。この手法自体も (1)文章をどのようにベクト\\nル表現化するか  (2)ベクトル表現化するための機械学習モデルをどのように作\\nるか (3)ベクトル表現化した後にどのように比較し指標化するか、等で多くの\\n工夫の余地があり、 Bilingual Evaluation Understudy with Representations \\nfrom Transformers (BLEURT) といったより洗練された手法も提案されている。\\nルールベースの手法を採用するのではなくベクトル表現化するための機械学習\\nモデルを fine tuning する選択肢も存在する。  \\nテキスト生成 AIの生成物と正解データのテキストをプロンプトに入れ、テキ\\nスト系生成 AIによって評価させる手法は、特に追加学習を必要としない、いわ\\nゆるzero-shot Learning でもかなりの性能が出るとされている。この考え方で、\\nMT-BenchやAlpacaEval 、日本語だと Rakuda Benchmark 等のベンチマーク手法\\nが開発されている (LLM-as-a-Judgeとも呼ばれる )。一方で、実施するための計\\n算コストが非常に高いため、この方法を使った場合は費用や開発リードタイム\\nの抑制効果が一番低い。  \\n総じて、人間と機械的評価手法の間だけでなく、機械的評価手法の中でも評\\n価の品質と実施のためのコストにトレードオフの関係がある。どの手法を採用\\nするかはプロジェクトの目標に応じて異なるため一概に正解は決められない。\\n一般論として、エンジニアがリリース前に手元で小さく改善する場合はコスト\\nのあまりかからない手法でテストと改善を高速に実施した方が良いが、求めら\\nれる生成物の要件によっては簡易な評価手法は適さないケースも十分ありうる\\nため、考慮を必要とする。', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 58})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RecursiveCharacterTextSplitterのインスタンスを作成します。チャンクサイズ1000,チャンクの重複サイズは150\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "\n",
        "# ドキュメントを分割します\n",
        "docs = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "lt0GBNSNOMSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8uh0rC8OPEc",
        "outputId": "073712c1-3e6b-43ba-fca1-c63e3c1da5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='テキスト生成 AI利活用におけるリスクへの対策ガイ\\nドブック（α版）  \\n2024（令和6）年 5月30日 \\nデジタル庁', metadata={'source': '/content/20240530_resources_generalitve-ai-guidebook_01.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 日本語対応しているモデルを指定する\n",
        "modelPath = \"sentence-transformers/stsb-xlm-r-multilingual\"\n",
        "\n",
        "# GPUを有効にする\n",
        "model_kwargs = {'device':'cuda'}\n",
        "\n",
        "# エンコードオプションをOFFにします。 'normalize_embeddings' to False\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "\n",
        "# 上記のオプションを有効にしてHuggingFaceEmbeddingsを初期化します。\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=modelPath,     # Provide the pre-trained model's path\n",
        "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
        "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgHNp3C-ORcA",
        "outputId": "ccb7f598-5630-447f-b63b-14b6fa819624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a test document.\"\n",
        "query_result = embeddings.embed_query(text)\n",
        "query_result[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tnnsUlNOWHY",
        "outputId": "d954ff16-d188-415a-a96e-ff422cb2b547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.1386953443288803, -0.1773158460855484, 0.7730242013931274]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "C0cWY57JPN1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"テキスト生成 AIの利活用について説明しているページは？\"\n",
        "searchDocs = db.similarity_search(question)\n",
        "print(searchDocs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNtD8uCzPQFf",
        "outputId": "dedbb330-b894-4757-f7e0-38ff77c79286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 １.２ 本文書で想定するテキスト生成 AIの利活用方法  \n",
            " \n",
            "本文書ではテキスト生成 AIを以下の 4つのユースケースを想定している。  \n",
            " \n",
            "➢ ユースケース 1. チャットインターフェースで サービス 利用者とインタ\n",
            "ラクティブに対話する機能としてテキスト生成 AIをオンライン処理で用\n",
            "いる \n",
            "➢ ユースケース 2. 大量の文章に対してラベル付けやテキストデータ変換、\n",
            "その他翻訳や要約や文章作成等の自然言語処理を行う機能としてテキス\n",
            "ト生成AIをバッチ処理で用いる  \n",
            "➢ ユースケース 3. 情報検索を目的としたサービスで検索エンジンの補助\n",
            "としてテキスト生成 AIをオンライン処理で用いる  \n",
            "➢ ユースケース 4. ダッシュボードやソースコード等を サービス 利用者の\n",
            "自然言語により記述可能にする機能としてテキスト生成 AIをオンライン\n",
            "処理で用いる  \n",
            " \n",
            "テキスト生成 AIの利活用でもっとも有名な OpenAI社のChatGPT はこの類型\n",
            "ではユースケース 1に該当する。テキスト生成 AIの利活用はチャット利用に限\n",
            "定されない。  \n",
            "ユースケース 2の一例は ２.２ ２） パブリックコメントの返答作成業務\n",
            "にテキスト生成 AIを適切に利活用するユースケース で詳細に述べる。  \n",
            "ユースケース 3の一例は ２．２  １） 情報検索サービスを国民向けに展開\n",
            "する事例でテキスト生成 AIを適切に利活用する方法 で詳細に述べる。  \n",
            "ユースケース 4の一例は ２．２  ４） 信頼できるデータベースと連携して\n",
            "テキスト生成 AIを適切に利活用するユースケース で詳細に述べる。  \n",
            "１.３ 本書の構成  \n",
            " \n",
            "本文書は実践ガイドブックをベースにし、そこに対してテキスト生成 AI固有\n",
            "のリスクや留意点を補足することを目指している。そこで、 「第３編第１章  実\n",
            "践ガイドブックの構成  Point.2 チェックリスト」の分類にならい、新サービ\n",
            "ス企画時、予算要求前、調達実施前、設計・開発時、サービス実施時の段階で\n",
            "検討すべきテキスト生成 AI固有のリスクとその軽減策を述べる。  \n",
            "１.４ 用語\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fugashi\n",
        "!pip install -q unidic_lite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD2dXssKgku4",
        "outputId": "ea5a85ad-6a47-4488-971c-e91f67c62f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidic_lite\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unidic_lite\n",
            "  Building wheel for unidic_lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic_lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=1773fe63f45fa9f14fb8a20f3d04274d2dc295ceb31f22d4dd75eb852fbc3157\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "Successfully built unidic_lite\n",
            "Installing collected packages: unidic_lite\n",
            "Successfully installed unidic_lite-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ipadic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS_LQMz0mI19",
        "outputId": "84a58c6e-26e3-4e75-b5c1-194b570e2a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 事前に学習されたモデルを読み込み、トークナイザーを作成する\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"tohoku-nlp/bert-base-japanese\")\n",
        "\n",
        "# 事前に学習されたBERTモデルを読み込み、質疑応答モデルを作成する\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"tohoku-nlp/bert-base-japanese\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "ba1f84a9c41a4789858c0355ad71f666",
            "705d911093554b58b865718828077f91",
            "34d3c17d97354854aa8ca8cb2c982892",
            "6240ccce1aed4aa487d68dcd5fe063a0",
            "c4cee855b2ff4b939cf22f3a1c8600bf",
            "3aefe87d87d54d12980c868c0b9004e7",
            "44b035844941488c938be313b1028a1e",
            "7f550d50cea1446da3e90d1915f973b5",
            "4c4db50717d84a0b813be57623529af9",
            "31a9860e03d941ef9bdfbb7346f4add9",
            "8018a3cbd97244eea06c4add55559eb4"
          ]
        },
        "id": "-ZZcVlNrgPdV",
        "outputId": "7f4810a1-1e26-4b8e-b470-d5941bedc36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba1f84a9c41a4789858c0355ad71f666"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at tohoku-nlp/bert-base-japanese and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用するモデルを定義します。\n",
        "model_name = \"tohoku-nlp/bert-base-japanese\"\n",
        "\n",
        "# 指定された事前学習モデルのトークナイザーをロードします。\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# モデルとトークナイザーを定義して質疑応答モデルのパイプラインを作成します。\n",
        "question_answerer = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=model_name,\n",
        "    tokenizer=tokenizer,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# HuggingFacePipelineのインスタンスを作成します。\n",
        "llm = HuggingFacePipeline(\n",
        "    pipeline=question_answerer,\n",
        "    model_kwargs={\"temperature\": 0.7, \"max_length\": 512},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipo-Lb7SPWcP",
        "outputId": "3233380e-8359-4161-dec8-fa7c347355db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at tohoku-nlp/bert-base-japanese and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "ayDE1GK1PY3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 最大4つの関連する分割/ドキュメントを取得する検索構成を使用して、「データベース」から取得オブジェクトを作成します。\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "# RetrievalQA クラスを使用して質問応答インスタンス (qa) を作成します。\n",
        "# 言語モデル (LLM)、chain_type \"refine\" で構成します。\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=retriever, return_source_documents=False)"
      ],
      "metadata": {
        "id": "KA7og5z0PdsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"生成AIを業務でのユースケースは?\"\n",
        "result = qa.run({\"query\": question})\n",
        "print(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "LBQRy6UpPfHV",
        "outputId": "a2202b73-c4f7-4e8c-8127-bc7392e6da99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Context information is below. \n------------\n39 ６.２ 非機能要件に関する実績データを把握しているか  \n1) チャット利用の場合  \nここではユースケースのうち、 チャットインターフェースで利用者サービス\n利用者とインタラクティブに対話する機能としてテキスト生成 AIをオンライン\n処理で用いるケース について述べる。  \nサービス利用者からの実際の入力がログの形で入手可能になり、それらがテ\nストケースに含まれていなかった場合、テストケースに追加することができる。\nこれは４．１  チャットでの利用 の期待品質  でも述べた。この実際の入力を\nベースとしたテストケースを用い、改めて品質評価を行うことで 非機能要件に\n関する実績データが得られる。 ただし、 ６．１  業務の実績データや利用者\n要望を分析できているか  で述べたように、重要な実績データである サービス\n利用者からの入力文の扱いはプライバシー侵害だとみなされないように注意す\nる。 \n2) バッチ処理での利用の場合  \nここではユースケースのうち、 大量の文章に対してラベル付けやテキストデ\nータ変換、その他翻訳や要約や文章作成等の自然言語処理を行う機能としてテ\nキスト生成 AIをバッチ処理で用いるケース について述べる。 ４．２  バッチ\n処理での利用 の期待品質  で述べたテストケースを実績データから増やし、そ\nれをテストすることで、非機能要件に関する実績データが得られる。  \n3) 情報検索での利用の場合  \nここではユースケースのうち、 情報検索を目的としたサービスで検索エンジ\nンの補助としてテキスト生成 AIをオンライン処理で用いるケース につい述べる。\n４．３  情報検索での利用 の期待品質  で述べたテストケースを実績データか\nら増やし、それをテストすることで、非機能要件に関する実績データが得られ\nる。 \n4) 自然言語からのプログラム作成での利用の場合  \nここではユースケースのうち、 ダッシュボードやソースコード等をサービス\n利用者の自然言語により記述可能にする機能としてテキスト生成 AIをオンライ\nン処理で用いるケース について述べる。 ４．４  自然言語からのプログラム\n作成での利用 の期待品質  で述べたテストケースを実績データから増やし、そ\nれをテストすることで、非機能要件に関する実績データが得られる。\n------------\nGiven the context information and not prior knowledge, answer the question: 生成AIを業務でのユースケースは?\n argument needs to be of type (SquadExample, dict)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-b35550fd98d3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"生成AIを業務でのユースケースは?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    601\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m         }\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/retrieval_qa/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         answer = self.combine_documents_chain.run(\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    606\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m         }\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mother_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/refine.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_initial_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_llm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mrefine_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m         }\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    632\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 )\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[0;32m--> 803\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    804\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             output = (\n\u001b[0;32m--> 657\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    658\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_pipeline.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;31m# Process batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             responses = self.pipeline(\n\u001b[0m\u001b[1;32m    274\u001b[0m                 \u001b[0mbatch_prompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mpipeline_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;31m# Convert inputs to features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mQuestionAnsweringPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{item} argument needs to be of type (SquadExample, dict)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Context information is below. \n------------\n39 ６.２ 非機能要件に関する実績データを把握しているか  \n1) チャット利用の場合  \nここではユースケースのうち、 チャットインターフェースで利用者サービス\n利用者とインタラクティブに対話する機能としてテキスト生成 AIをオンライン\n処理で用いるケース について述べる。  \nサービス利用者からの実際の入力がログの形で入手可能になり、それらがテ\nストケースに含まれていなかった場合、テストケースに追加することができる。\nこれは４．１  チャットでの利用 の期待品質  でも述べた。この実際の入力を\nベースとしたテストケースを用い、改めて品質評価を行うことで 非機能要件に\n関する実績データが得られる。 ただし、 ６．１  業務の実績データや利用者\n要望を分析できているか  で述べたように、重要な実績データである サービス\n利用者からの入力文の扱いはプライバシー侵害だとみなされないように注意す\nる。 \n2) バッチ処理での利用の場合  \nここではユースケースのうち、 大量の文章に対してラベル付けやテキストデ\nータ変換、その他翻訳や要約や文章作成等の自然言語処理を行う機能としてテ\nキスト生成 AIをバッチ処理で用いるケース について述べる。 ４．２  バッチ\n処理での利用 の期待品質  で述べたテストケースを実績データから増やし、そ\nれをテストすることで、非機能要件に関する実績データが得られる。  \n3) 情報検索での利用の場合  \nここではユースケースのうち、 情報検索を目的としたサービスで検索エンジ\nンの補助としてテキスト生成 AIをオンライン処理で用いるケース につい述べる。\n４．３  情報検索での利用 の期待品質  で述べたテストケースを実績データか\nら増やし、それをテストすることで、非機能要件に関する実績データが得られ\nる。 \n4) 自然言語からのプログラム作成での利用の場合  \nここではユースケースのうち、 ダッシュボードやソースコード等をサービス\n利用者の自然言語により記述可能にする機能としてテキスト生成 AIをオンライ\nン処理で用いるケース について述べる。 ４．４  自然言語からのプログラム\n作成での利用 の期待品質  で述べたテストケースを実績データから増やし、そ\nれをテストすることで、非機能要件に関する実績データが得られる。\n------------\nGiven the context information and not prior knowledge, answer the question: 生成AIを業務でのユースケースは?\n argument needs to be of type (SquadExample, dict)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"生成AIの利用上のリスクは?\"\n",
        "result = qa.run({\"query\": question})\n",
        "print(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "eBR2OzDWk_0Q",
        "outputId": "39b468b2-a9be-4191-93b1-5f854174f5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Context information is below. \n------------\n40 ６.３ 業務で扱うデータの品質を維持しつつ適切なライフサイクル管理を\n行っているか  \n \n一般的なシステム開発のデータ品質とライフサイクル管理はデータの不整合\nの発生抑止に重視が置かれるが、ここでは AIプロジェクトの観点でのデータの\nライフサイクルについて述べる。これは、 (1)実際の利用 実績が当初想定から\n乖離あるいは変化、 (2)利用した機械学習モデル (ここでは大規模言語モデル )\nの変化、の 2つの変化により機能要件・非機能要件を満たさなくなるリスクの\nことを指す。機能要件が満たされているかの監視は一般的なシステム開発でも\n共通した話であり、非機能要件が満たされているかの監視については ６．２  \n非機能要件に関する実績データを把握しているか  で述べたので割愛する。  \n機能要件・非機能要件が満たされなくなる前に気が付く、満たされなくなっ\nた後に原因分析を行い適切な対策をとる、の両方のために、原因となる変化を\n観測することは非常に重要である。仮にシステムが機能要件・非機能要件を満\nたさなくなった場合、その要件を再び満たすための改修だけでなく、サービス\nの停止や終了も視野にいれた検討も視野に入れるべきである。  \n(1)実際の利用実績が当初想定から乖離あるいは変化したか、についての観\n測は６．１  業務の実績データや利用者要望を分析できているか  で述べた。\n特にサービス実施直後は、設計・開発時との想定との乖離がないかをしっかり\nと確認することを推奨する。  \n(2)利用した機械学習モデル (ここでは大規模言語モデル )の変化については、\nテキスト生成 AIの機械学習モデルが直接提供されるケース以外の利用形態につ\nいては注意すべき点であり、付録の ７．１ ４）アップデート対応に関する\nリスクと７．２．４） アップデート対応に関するリスク を参照していただき\nたい。  \n６.４ ６章 まとめ \nサービス実施時には、実際の運用データをもとにした継続的な品質評価が必\n要である。本章では、業務実績データの分析と非機能要件の達成度の検証に焦\n点を当て、適切なライフサイクル管理を通じて、サービスの持続可能性を保証\nするための留意点を強調した。これらの実施により、テキスト生成 AIの持続的\nな価値提供が実現できる。\n------------\nGiven the context information and not prior knowledge, answer the question: 生成AIの利用上のリスクは?\n argument needs to be of type (SquadExample, dict)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-fc65826e3d59>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"生成AIの利用上のリスクは?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    601\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m         }\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/retrieval_qa/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         answer = self.combine_documents_chain.run(\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    606\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m         }\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mother_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/refine.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_initial_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_llm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mrefine_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m         }\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    632\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 )\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[0;32m--> 803\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    804\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             output = (\n\u001b[0;32m--> 657\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    658\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_pipeline.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;31m# Process batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             responses = self.pipeline(\n\u001b[0m\u001b[1;32m    274\u001b[0m                 \u001b[0mbatch_prompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mpipeline_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;31m# Convert inputs to features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mQuestionAnsweringPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{item} argument needs to be of type (SquadExample, dict)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Context information is below. \n------------\n40 ６.３ 業務で扱うデータの品質を維持しつつ適切なライフサイクル管理を\n行っているか  \n \n一般的なシステム開発のデータ品質とライフサイクル管理はデータの不整合\nの発生抑止に重視が置かれるが、ここでは AIプロジェクトの観点でのデータの\nライフサイクルについて述べる。これは、 (1)実際の利用 実績が当初想定から\n乖離あるいは変化、 (2)利用した機械学習モデル (ここでは大規模言語モデル )\nの変化、の 2つの変化により機能要件・非機能要件を満たさなくなるリスクの\nことを指す。機能要件が満たされているかの監視は一般的なシステム開発でも\n共通した話であり、非機能要件が満たされているかの監視については ６．２  \n非機能要件に関する実績データを把握しているか  で述べたので割愛する。  \n機能要件・非機能要件が満たされなくなる前に気が付く、満たされなくなっ\nた後に原因分析を行い適切な対策をとる、の両方のために、原因となる変化を\n観測することは非常に重要である。仮にシステムが機能要件・非機能要件を満\nたさなくなった場合、その要件を再び満たすための改修だけでなく、サービス\nの停止や終了も視野にいれた検討も視野に入れるべきである。  \n(1)実際の利用実績が当初想定から乖離あるいは変化したか、についての観\n測は６．１  業務の実績データや利用者要望を分析できているか  で述べた。\n特にサービス実施直後は、設計・開発時との想定との乖離がないかをしっかり\nと確認することを推奨する。  \n(2)利用した機械学習モデル (ここでは大規模言語モデル )の変化については、\nテキスト生成 AIの機械学習モデルが直接提供されるケース以外の利用形態につ\nいては注意すべき点であり、付録の ７．１ ４）アップデート対応に関する\nリスクと７．２．４） アップデート対応に関するリスク を参照していただき\nたい。  \n６.４ ６章 まとめ \nサービス実施時には、実際の運用データをもとにした継続的な品質評価が必\n要である。本章では、業務実績データの分析と非機能要件の達成度の検証に焦\n点を当て、適切なライフサイクル管理を通じて、サービスの持続可能性を保証\nするための留意点を強調した。これらの実施により、テキスト生成 AIの持続的\nな価値提供が実現できる。\n------------\nGiven the context information and not prior knowledge, answer the question: 生成AIの利用上のリスクは?\n argument needs to be of type (SquadExample, dict)"
          ]
        }
      ]
    }
  ]
}